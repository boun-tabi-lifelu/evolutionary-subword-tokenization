{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pandarallel import pandarallel\n",
    "from time import time\n",
    "from tokenizers import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import linregress\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.mapslim import mapslim\n",
    "from goatools.gosubdag.gosubdag import GoSubDag\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from bertopic.backend import BaseEmbedder\n",
    "from bertopic.cluster import BaseCluster\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.dimensionality import BaseDimensionalityReduction\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "from typing import List, Dict, Tuple, Set, Any, Optional, Union\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from vocabulary_functions import get_mutated, get_parents, set_difference, set_intersection, load_tokenizers, calc_agreement, calc_dice_idx_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 20 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(nb_workers=20, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go-basic.obo: fmt(1.2) rel(2025-03-16) 43,544 Terms\n",
      "goslim_generic.obo: fmt(1.2) rel(go/2025-03-16/subsets/goslim_generic.owl) 206 Terms\n",
      " GoSubDag: 206 sources in 335 GOs rcnt(True). 65 alt GO IDs\n",
      " GoSubDag: namedtuple fields: NS level depth GO alt GO_name dcnt D1 id\n",
      " GoSubDag: relationships: set()\n"
     ]
    }
   ],
   "source": [
    "# Download GO DAG (ontology structure)\n",
    "obo_url = \"http://purl.obolibrary.org/obo/go/go-basic.obo\"\n",
    "obo_path = \"go-basic.obo\"\n",
    "\n",
    "# Download OBO file if not already downloaded\n",
    "if not os.path.exists(obo_path):\n",
    "    with open(obo_path, \"w\") as f:\n",
    "        f.write(requests.get(obo_url).text)\n",
    "\n",
    "# Parse GO DAG\n",
    "go_dag = GODag(obo_path)\n",
    "\n",
    "# Download GO Slim generic terms\n",
    "goslim_url = \"http://current.geneontology.org/ontology/subsets/goslim_generic.obo\"\n",
    "goslim_path = \"goslim_generic.obo\"\n",
    "\n",
    "if not os.path.exists(goslim_path):\n",
    "    with open(goslim_path, \"w\") as f:\n",
    "        f.write(requests.get(goslim_url).text)\n",
    "\n",
    "# Parse GO Slim DAG\n",
    "goslim_dag = GODag(goslim_path)\n",
    "goslim_terms = set(goslim_dag.keys())\n",
    "\n",
    "go_subdag_slim = GoSubDag(goslim_terms, go_dag)\n",
    "\n",
    "goslim_id2name = {go_id : go_dag[go_id].name for go_id in goslim_terms}\n",
    "goslim_name2id = {go_dag[go_id].name : go_id for go_id in goslim_terms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dataset': {'uniref50', 'uniref90'}\n",
    "# 'is_pretokenizer': {True, False}\n",
    "# 'subs_matrix': {'blosum45', 'blosum62', 'pam70', 'pam250'}\n",
    "# 'mutation_cutoff': {0.7, 0.8, 0.9}\n",
    "# 'min_mutation_freq': {0, 0.05,. 0.005}\n",
    "# 'min_mutation_len': {3}\n",
    "# 'max_mutation_len': {12}\n",
    "# 'vocab_size': list=[800, 1600, 3200, 6400, 12800, 25600, 51200]\n",
    "\n",
    "vocab_sizes = [800, 1600, 3200, 6400, 12800, 25600]\n",
    "vocab_sizes = [6400, 12800, 25600]\n",
    "uniref_id = \"50\"\n",
    "\n",
    "tokenizer_opts_list = [\n",
    "    {\n",
    "        'is_mut': True,\n",
    "        'dataset': f'uniref{uniref_id}',\n",
    "        'is_pretokenizer': False,\n",
    "        'subs_matrix': 'blosum62',\n",
    "        'mutation_cutoff': 0.7,\n",
    "        'min_mutation_freq': 0.05,\n",
    "        'min_mutation_len': 3,\n",
    "        'max_mutation_len': 12,\n",
    "        'vocab_size': vocab_sizes\n",
    "    },\n",
    "    # {\n",
    "    #     'is_mut': True,\n",
    "    #     'dataset': f'uniref{uniref_id}',\n",
    "    #     'is_pretokenizer': False,\n",
    "    #     'subs_matrix': 'pam70',\n",
    "    #     'mutation_cutoff': 0.7,\n",
    "    #     'min_mutation_freq': 0.05,\n",
    "    #     'min_mutation_len': 3,\n",
    "    #     'max_mutation_len': 12,\n",
    "    #     'vocab_size': vocab_sizes\n",
    "    # },\n",
    "    # {\n",
    "    #     'is_mut': True,\n",
    "    #     'dataset': f'uniref{uniref_id}',\n",
    "    #     'is_pretokenizer': True,\n",
    "    #     'subs_matrix': 'blosum62',\n",
    "    #     'mutation_cutoff': 0.7,\n",
    "    #     'min_mutation_freq': 0.05,\n",
    "    #     'min_mutation_len': 3,\n",
    "    #     'max_mutation_len': 12,\n",
    "    #     'vocab_size': vocab_sizes\n",
    "    # },\n",
    "    {\n",
    "        'is_mut': True,\n",
    "        'dataset': f'uniref{uniref_id}',\n",
    "        'is_pretokenizer': True,\n",
    "        'subs_matrix': 'pam70',\n",
    "        'mutation_cutoff': 0.7,\n",
    "        'min_mutation_freq': 0.05,\n",
    "        'min_mutation_len': 3,\n",
    "        'max_mutation_len': 12,\n",
    "        'vocab_size': vocab_sizes\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_list = load_tokenizers(tokenizer_opts_list, 'hf')\n",
    "inner_vocab_list = load_tokenizers(tokenizer_opts_list, 'vocab')\n",
    "\n",
    "vocab_list = {}\n",
    "for name, tokenizer in tokenizer_list.items():\n",
    "    vocab_list[name] = list(set([token for token, idx in tokenizer.get_vocab().items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PUMA blosum62 0.7 0.05': 'PUMA BLOSUM62 0.7 0.05',\n",
       " 'PUMA pre pam70 0.7 0.05': 'PUMA Pre PAM70 0.7 0.05'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = [method_name[:-len(str(vocab_sizes[0]))-1] for method_name in list(tokenizer_list.keys())[::len(vocab_sizes)]]\n",
    "methods2names = {mn:mn.replace('mut', 'evo').replace('std', '').replace('blosum', 'BLOSUM').replace('pam', 'PAM').replace('pre', 'Pre') for mn in methods}\n",
    "methods2names = {k: ' '.join(v.split()[:-2]) if 'evoBPE' in v else v for k, v in methods2names.items()}\n",
    "methods2names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 47.65it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_lineage_list = {}\n",
    "for k, v in inner_vocab_list.items():\n",
    "    template_dict = {\n",
    "        \n",
    "    }\n",
    "    vocab_lineage_list[k] = {token:{\n",
    "                                'frequency': -1,\n",
    "                                'order': -1,\n",
    "                                'parent_pair': [],\n",
    "                                'parent_mutation': \"\",\n",
    "                                'parent_mutation_similarity': -1,\n",
    "                                'partner_pair_self': False,\n",
    "                                'partner_pair_left': [],\n",
    "                                'partner_pair_right': [],\n",
    "                                'child_pair': [],\n",
    "                                'child_mutation': []\n",
    "                            } for token in v.keys()}\n",
    "\n",
    "for method_name, vocab in tqdm(inner_vocab_list.items()):\n",
    "    for token, inner_vocab_elements in vocab.items():\n",
    "        vocab_lineage_list[method_name][token]['frequency'] = inner_vocab_elements['frequency']\n",
    "        vocab_lineage_list[method_name][token]['order'] = inner_vocab_elements['order']\n",
    "        vocab_lineage_list[method_name][token]['parent_pair'] = inner_vocab_elements['pair'] if 'pair' in inner_vocab_elements else []\n",
    "        vocab_lineage_list[method_name][token]['parent_mutation'] = inner_vocab_elements['parent'] if 'parent' in inner_vocab_elements else \"\"\n",
    "        vocab_lineage_list[method_name][token]['parent_mutation_similarity'] = inner_vocab_elements['similarity'] if 'similarity' in inner_vocab_elements else -1\n",
    "\n",
    "        if 'pair' in inner_vocab_elements:\n",
    "            if inner_vocab_elements['pair'][0] == inner_vocab_elements['pair'][1]:\n",
    "                vocab_lineage_list[method_name][inner_vocab_elements['pair'][0]]['partner_pair_self'] = True\n",
    "                vocab_lineage_list[method_name][inner_vocab_elements['pair'][0]]['child_pair'].append(token)\n",
    "            else:\n",
    "                vocab_lineage_list[method_name][inner_vocab_elements['pair'][0]]['partner_pair_right'].append(inner_vocab_elements['pair'][1])\n",
    "                vocab_lineage_list[method_name][inner_vocab_elements['pair'][1]]['partner_pair_left'].append(inner_vocab_elements['pair'][0])\n",
    "                vocab_lineage_list[method_name][inner_vocab_elements['pair'][0]]['child_pair'].append(token)\n",
    "                vocab_lineage_list[method_name][inner_vocab_elements['pair'][1]]['child_pair'].append(token)\n",
    "        if 'parent' in inner_vocab_elements:\n",
    "                vocab_lineage_list[method_name][inner_vocab_elements['parent']]['child_mutation'].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB\n",
    "db_file = \"/cta/share/users/uniprot/human/human.db\"\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "df_protein = pd.read_sql(f\"\"\"SELECT Entry as uniprot_id, Sequence as sequence\n",
    "                          FROM proteins\n",
    "                          WHERE Entry IN (SELECT uniprot_accession FROM uniref{uniref_id}_distilled)\"\"\", conn)\n",
    "df_protein = df_protein[df_protein['sequence'].str.len() < 3000].reset_index(drop=True)\n",
    "\n",
    "df_protein_sliced = pd.read_sql(f\"SELECT uniprot_id, sequence FROM uniref{uniref_id}_domain_sliced_plddt70\", conn)\n",
    "df_protein_sliced = df_protein_sliced[df_protein_sliced['uniprot_id'].isin(df_protein['uniprot_id'])].reset_index(drop=True)\n",
    "\n",
    "df_quickgo = pd.read_sql(f\"SELECT uniprot_id, go_id, go_evidence FROM uniprot_quickgo_annotations\", conn)\n",
    "df_quickgo = df_quickgo[df_quickgo['uniprot_id'].isin(df_protein['uniprot_id'])]\n",
    "\n",
    "# Filter by evidence code\n",
    "go_evidence_experimental = ['EXP', 'IDA', 'IPI', 'IMP', 'IGI', 'IEP']\n",
    "go_evidence_computational = ['ISS', 'ISO', 'ISA', 'ISM', 'RCA', 'TAS', 'IEA']\n",
    "df_quickgo = df_quickgo[df_quickgo['go_evidence'].isin(go_evidence_experimental+go_evidence_computational)].reset_index(drop=True)\n",
    "\n",
    "# Convert go_ids to go_slim_ids\n",
    "df_quickgo['go_slim_id'] = df_quickgo['go_id'].apply(lambda x: list(mapslim(x, go_dag, goslim_dag)[0]) if x in go_dag else [])\n",
    "df_quickgo['go_slim_id'] = df_quickgo['go_slim_id'].apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "df_quickgo = df_quickgo[df_quickgo['go_slim_id'] != '']\n",
    "\n",
    "# Drop duplicates\n",
    "# df_quickgo = df_quickgo.drop_duplicates(subset=['uniprot_id', 'go_slim_id']).drop(columns=['go_id', 'go_evidence']).rename(columns={'go_slim_id': 'go_id'}).reset_index(drop=True)\n",
    "df_quickgo = df_quickgo.groupby(['uniprot_id', 'go_slim_id']).count().reset_index().sort_values(['uniprot_id', 'go_id'], ascending=False)\n",
    "df_quickgo = df_quickgo.drop(columns=['go_id', 'go_evidence']).rename(columns={'go_slim_id': 'go_id'}).reset_index(drop=True)\n",
    "\n",
    "# # Drop infrequent go terms\n",
    "df_quickgo = df_quickgo[df_quickgo['go_id'].isin(df_quickgo['go_id'].value_counts()[df_quickgo['go_id'].value_counts()>20].index)].reset_index(drop=True)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>go_id</th>\n",
       "      <th>go_name</th>\n",
       "      <th>go_aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X6RLR1</td>\n",
       "      <td>GO:0000910</td>\n",
       "      <td>cytokinesis</td>\n",
       "      <td>biological_process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X6RLR1</td>\n",
       "      <td>GO:0005730</td>\n",
       "      <td>nucleolus</td>\n",
       "      <td>cellular_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X6RLR1</td>\n",
       "      <td>GO:0005829</td>\n",
       "      <td>cytosol</td>\n",
       "      <td>cellular_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X6RLN4</td>\n",
       "      <td>GO:0005829</td>\n",
       "      <td>cytosol</td>\n",
       "      <td>cellular_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X6RL45</td>\n",
       "      <td>GO:0016787</td>\n",
       "      <td>hydrolase activity</td>\n",
       "      <td>molecular_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141480</th>\n",
       "      <td>A0A024CHX5</td>\n",
       "      <td>GO:0016787</td>\n",
       "      <td>hydrolase activity</td>\n",
       "      <td>molecular_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141481</th>\n",
       "      <td>A0A024CHX5</td>\n",
       "      <td>GO:0005576</td>\n",
       "      <td>extracellular region</td>\n",
       "      <td>cellular_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141482</th>\n",
       "      <td>A0A023T4H3</td>\n",
       "      <td>GO:0140096</td>\n",
       "      <td>catalytic activity, acting on a protein</td>\n",
       "      <td>molecular_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141483</th>\n",
       "      <td>A0A023IQH3</td>\n",
       "      <td>GO:0007155</td>\n",
       "      <td>cell adhesion</td>\n",
       "      <td>biological_process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141484</th>\n",
       "      <td>A0A023HJ61</td>\n",
       "      <td>GO:0003924</td>\n",
       "      <td>GTPase activity</td>\n",
       "      <td>molecular_function</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141485 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uniprot_id       go_id                                  go_name  \\\n",
       "0           X6RLR1  GO:0000910                              cytokinesis   \n",
       "1           X6RLR1  GO:0005730                                nucleolus   \n",
       "2           X6RLR1  GO:0005829                                  cytosol   \n",
       "3           X6RLN4  GO:0005829                                  cytosol   \n",
       "4           X6RL45  GO:0016787                       hydrolase activity   \n",
       "...            ...         ...                                      ...   \n",
       "141480  A0A024CHX5  GO:0016787                       hydrolase activity   \n",
       "141481  A0A024CHX5  GO:0005576                     extracellular region   \n",
       "141482  A0A023T4H3  GO:0140096  catalytic activity, acting on a protein   \n",
       "141483  A0A023IQH3  GO:0007155                            cell adhesion   \n",
       "141484  A0A023HJ61  GO:0003924                          GTPase activity   \n",
       "\n",
       "                 go_aspect  \n",
       "0       biological_process  \n",
       "1       cellular_component  \n",
       "2       cellular_component  \n",
       "3       cellular_component  \n",
       "4       molecular_function  \n",
       "...                    ...  \n",
       "141480  molecular_function  \n",
       "141481  cellular_component  \n",
       "141482  molecular_function  \n",
       "141483  biological_process  \n",
       "141484  molecular_function  \n",
       "\n",
       "[141485 rows x 4 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quickgo['go_name'] = df_quickgo['go_id'].apply(lambda go_id: go_dag[go_id].name)\n",
    "df_quickgo['go_aspect'] = df_quickgo['go_id'].apply(lambda go_id: go_dag[go_id].namespace)\n",
    "df_quickgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "go_aspect\n",
       "cellular_component    53180\n",
       "biological_process    46393\n",
       "molecular_function    41912\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quickgo['go_aspect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "go_name\n",
       "nucleus                       9249\n",
       "plasma membrane               6163\n",
       "cytosol                       6135\n",
       "transferase activity          5981\n",
       "nucleoplasm                   5385\n",
       "                              ... \n",
       "molecular sensor activity       37\n",
       "respiratory system process      33\n",
       "cytoplasmic translation         32\n",
       "antioxidant activity            31\n",
       "cyclase activity                30\n",
       "Name: count, Length: 126, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quickgo['go_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:13<00:00,  2.32s/it]\n"
     ]
    }
   ],
   "source": [
    "for name, tokenizer in tqdm(list(tokenizer_list.items())):\n",
    "    if 'pre' in name:\n",
    "        df_protein_sliced[name] = [enc.tokens for enc in tokenizer.encode_batch(df_protein_sliced['sequence'])]\n",
    "    else:\n",
    "        df_protein[name] = [enc.tokens for enc in tokenizer.encode_batch(df_protein['sequence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>PUMA blosum62 0.7 0.05 6400</th>\n",
       "      <th>PUMA blosum62 0.7 0.05 12800</th>\n",
       "      <th>PUMA blosum62 0.7 0.05 25600</th>\n",
       "      <th>PUMA pre pam70 0.7 0.05 6400</th>\n",
       "      <th>PUMA pre pam70 0.7 0.05 12800</th>\n",
       "      <th>PUMA pre pam70 0.7 0.05 25600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A087WZT3</td>\n",
       "      <td>MELSAEYLREKLQRDLEAEHVLPSPGGVGQVRGETAASETQLGS</td>\n",
       "      <td>[MEL, SA, EYL, R, EKL, QR, DL, EA, EH, VL, PSP...</td>\n",
       "      <td>[MEL, SA, EYL, REKL, QRDL, EAEH, VL, PSP, GG, ...</td>\n",
       "      <td>[MEL, SA, EYL, REKL, QRDL, EAEH, VL, PSP, GGVG...</td>\n",
       "      <td>[MEL, SA, EYL, REKL, QRDL, EA, EH, VL, PSP, GG...</td>\n",
       "      <td>[MEL, SA, EYL, REKL, QRDL, EA, EHVL, PSP, GGVG...</td>\n",
       "      <td>[MEL, SA, EYL, REKL, QRDL, EA, EHVL, PSP, GGVG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A087X1C5</td>\n",
       "      <td>MGLEALVPLAMIVAIFLLLVDLMHRHQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A087X296</td>\n",
       "      <td>MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGIC...</td>\n",
       "      <td>[M, SR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, ...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...</td>\n",
       "      <td>[MSR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, PG...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0B4J2F0</td>\n",
       "      <td>MFRRLTFAQLLFATVLGIAGGVYIFQPVFEQYAKDQKELKEKMQLV...</td>\n",
       "      <td>[M, FR, RL, TFA, QLL, FA, T, VLG, IA, GGV, YI,...</td>\n",
       "      <td>[M, FR, RL, TFA, QLL, FA, T, VLG, IA, GGV, YI,...</td>\n",
       "      <td>[M, FRRL, TFA, QLL, FAT, VLG, IA, GGV, YI, FQ,...</td>\n",
       "      <td>[M, FR, RL, TFA, QLL, FA, TVL, GIA, GGV, YI, F...</td>\n",
       "      <td>[M, FRRL, TFA, QLL, FA, TVL, GIA, GGV, YI, FQ,...</td>\n",
       "      <td>[M, FRRL, TFA, QLL, FA, TVL, GIA, GGV, YI, FQ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0C5B5G6</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>[M, RW, QE, MG, YI, FY, PR, KL, R]</td>\n",
       "      <td>[M, RW, QEMG, YI, FY, PRKL, R]</td>\n",
       "      <td>[MRW, QEMG, YI, FY, PRKL, R]</td>\n",
       "      <td>[M, RW, QE, MG, YI, FY, PR, KL, R]</td>\n",
       "      <td>[M, RW, QE, MG, YI, FY, PR, KL, R]</td>\n",
       "      <td>[M, RW, QE, MG, YI, FY, PRKL, R]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>X6RL83</td>\n",
       "      <td>MLQEWLAAVGDDYAAVVWRPEGEPRFYPDEEGPKHWTKERHQFLME...</td>\n",
       "      <td>[ML, QE, WL, AAVG, DDY, AA, VV, W, RP, EG, EPR...</td>\n",
       "      <td>[ML, QE, WL, AAVG, DDY, AA, VVW, RPEG, EPR, FY...</td>\n",
       "      <td>[ML, QE, WL, AAVG, DDY, AA, VVW, RPEG, EPR, FY...</td>\n",
       "      <td>[M, L, QE, WL, AAVG, DD, YAA, VV, W, RP, EG, E...</td>\n",
       "      <td>[M, L, QE, WL, AAVG, DD, YAA, VV, W, RP, EG, E...</td>\n",
       "      <td>[M, L, QE, WL, AAVG, DD, YAA, VV, W, RPEG, EPR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>X6RLN4</td>\n",
       "      <td>EVKGLFKSENCPKVISCEFAHNSNWYITFQSDTDAQQAFKYLREEV...</td>\n",
       "      <td>[EV, KGL, FK, SEN, C, P, KVI, SC, EFA, HN, SN,...</td>\n",
       "      <td>[EV, KGL, FK, SEN, C, PKVI, SC, EFA, HN, SN, W...</td>\n",
       "      <td>[EV, KGL, FK, SEN, C, PKVI, SC, EFA, HN, SN, W...</td>\n",
       "      <td>[EV, KGL, FK, SEN, C, P, KVI, SC, EFA, HN, SNW...</td>\n",
       "      <td>[EV, KGL, FK, SEN, CP, KVI, SC, EFA, HN, SNW, ...</td>\n",
       "      <td>[EV, KGL, FK, SEN, CP, KVI, SC, EFA, HN, SNW, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>X6RLR1</td>\n",
       "      <td>MAGLTDLQRLQARVEELERWVYGPGGARGSRKVADGLVKVQVALGN...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QARV, EEL, ER, WV, YG, PGG,...</td>\n",
       "      <td>[MA, GL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MAGL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PGG,...</td>\n",
       "      <td>[MAGL, TDL, QRL, QARV, EEL, ER, WV, YG, PGG, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>X6RLV5</td>\n",
       "      <td>MSGYSSDRDRGRDRGFGAPRFGGSRAGPLSGKKFGNPGEKLVKKKW...</td>\n",
       "      <td>[MSG, YSS, DRD, RG, RD, RG, FGA, PRF, GG, SRAG...</td>\n",
       "      <td>[MSG, YSS, DRD, RG, RD, RG, FGA, PRF, GG, SRAG...</td>\n",
       "      <td>[MSG, YSS, DRD, RG, RDRG, FGA, PRF, GG, SRAG, ...</td>\n",
       "      <td>[MSG, Y, SSD, RD, RG, RD, RG, FGA, PR, FGG, SR...</td>\n",
       "      <td>[MSG, Y, SSD, RD, RG, RD, RG, FGA, PR, FGG, SR...</td>\n",
       "      <td>[MSG, Y, SSD, RD, RGRD, RG, FGA, PR, FGG, SRAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>X6RM24</td>\n",
       "      <td>XHGADAMHTDPDYSAAYVVIETDAEDGIKGCGITFTLGKGTEVDWS...</td>\n",
       "      <td>[X, HGA, DAM, HTD, PDY, SAA, YVV, I, ET, DA, E...</td>\n",
       "      <td>[X, HGA, DAM, HTD, PDY, SAA, YVV, I, ET, DA, E...</td>\n",
       "      <td>[X, HGA, DAM, HTD, PDY, SAA, YVV, I, ETDA, EDG...</td>\n",
       "      <td>[X, HG, ADA, MH, TD, PD, Y, SAA, Y, VVI, ET, D...</td>\n",
       "      <td>[X, HG, ADA, MH, TD, PDY, SAA, Y, VVI, ET, DAE...</td>\n",
       "      <td>[X, HG, ADA, MH, TD, PDY, SAA, Y, VVI, ET, DAE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70692 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uniprot_id                                           sequence  \\\n",
       "0      A0A087WZT3       MELSAEYLREKLQRDLEAEHVLPSPGGVGQVRGETAASETQLGS   \n",
       "1      A0A087X1C5  MGLEALVPLAMIVAIFLLLVDLMHRHQRWAARYPPGPLPLPGLGNL...   \n",
       "2      A0A087X296  MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGIC...   \n",
       "3      A0A0B4J2F0  MFRRLTFAQLLFATVLGIAGGVYIFQPVFEQYAKDQKELKEKMQLV...   \n",
       "4      A0A0C5B5G6                                   MRWQEMGYIFYPRKLR   \n",
       "...           ...                                                ...   \n",
       "70687      X6RL83  MLQEWLAAVGDDYAAVVWRPEGEPRFYPDEEGPKHWTKERHQFLME...   \n",
       "70688      X6RLN4  EVKGLFKSENCPKVISCEFAHNSNWYITFQSDTDAQQAFKYLREEV...   \n",
       "70689      X6RLR1  MAGLTDLQRLQARVEELERWVYGPGGARGSRKVADGLVKVQVALGN...   \n",
       "70690      X6RLV5  MSGYSSDRDRGRDRGFGAPRFGGSRAGPLSGKKFGNPGEKLVKKKW...   \n",
       "70691      X6RM24  XHGADAMHTDPDYSAAYVVIETDAEDGIKGCGITFTLGKGTEVDWS...   \n",
       "\n",
       "                             PUMA blosum62 0.7 0.05 6400  \\\n",
       "0      [MEL, SA, EYL, R, EKL, QR, DL, EA, EH, VL, PSP...   \n",
       "1      [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "2      [M, SR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, ...   \n",
       "3      [M, FR, RL, TFA, QLL, FA, T, VLG, IA, GGV, YI,...   \n",
       "4                     [M, RW, QE, MG, YI, FY, PR, KL, R]   \n",
       "...                                                  ...   \n",
       "70687  [ML, QE, WL, AAVG, DDY, AA, VV, W, RP, EG, EPR...   \n",
       "70688  [EV, KGL, FK, SEN, C, P, KVI, SC, EFA, HN, SN,...   \n",
       "70689  [MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "70690  [MSG, YSS, DRD, RG, RD, RG, FGA, PRF, GG, SRAG...   \n",
       "70691  [X, HGA, DAM, HTD, PDY, SAA, YVV, I, ET, DA, E...   \n",
       "\n",
       "                            PUMA blosum62 0.7 0.05 12800  \\\n",
       "0      [MEL, SA, EYL, REKL, QRDL, EAEH, VL, PSP, GG, ...   \n",
       "1      [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "2      [MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...   \n",
       "3      [M, FR, RL, TFA, QLL, FA, T, VLG, IA, GGV, YI,...   \n",
       "4                         [M, RW, QEMG, YI, FY, PRKL, R]   \n",
       "...                                                  ...   \n",
       "70687  [ML, QE, WL, AAVG, DDY, AA, VVW, RPEG, EPR, FY...   \n",
       "70688  [EV, KGL, FK, SEN, C, PKVI, SC, EFA, HN, SN, W...   \n",
       "70689  [MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "70690  [MSG, YSS, DRD, RG, RD, RG, FGA, PRF, GG, SRAG...   \n",
       "70691  [X, HGA, DAM, HTD, PDY, SAA, YVV, I, ET, DA, E...   \n",
       "\n",
       "                            PUMA blosum62 0.7 0.05 25600  \\\n",
       "0      [MEL, SA, EYL, REKL, QRDL, EAEH, VL, PSP, GGVG...   \n",
       "1      [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "2      [MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...   \n",
       "3      [M, FRRL, TFA, QLL, FAT, VLG, IA, GGV, YI, FQ,...   \n",
       "4                           [MRW, QEMG, YI, FY, PRKL, R]   \n",
       "...                                                  ...   \n",
       "70687  [ML, QE, WL, AAVG, DDY, AA, VVW, RPEG, EPR, FY...   \n",
       "70688  [EV, KGL, FK, SEN, C, PKVI, SC, EFA, HN, SN, W...   \n",
       "70689  [MA, GLT, DL, QRL, QARV, EEL, ER, WV, YG, PGG,...   \n",
       "70690  [MSG, YSS, DRD, RG, RDRG, FGA, PRF, GG, SRAG, ...   \n",
       "70691  [X, HGA, DAM, HTD, PDY, SAA, YVV, I, ETDA, EDG...   \n",
       "\n",
       "                            PUMA pre pam70 0.7 0.05 6400  \\\n",
       "0      [MEL, SA, EYL, REKL, QRDL, EA, EH, VL, PSP, GG...   \n",
       "1      [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...   \n",
       "2      [MSR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, PG...   \n",
       "3      [M, FR, RL, TFA, QLL, FA, TVL, GIA, GGV, YI, F...   \n",
       "4                     [M, RW, QE, MG, YI, FY, PR, KL, R]   \n",
       "...                                                  ...   \n",
       "70687  [M, L, QE, WL, AAVG, DD, YAA, VV, W, RP, EG, E...   \n",
       "70688  [EV, KGL, FK, SEN, C, P, KVI, SC, EFA, HN, SNW...   \n",
       "70689  [MA, GL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "70690  [MSG, Y, SSD, RD, RG, RD, RG, FGA, PR, FGG, SR...   \n",
       "70691  [X, HG, ADA, MH, TD, PD, Y, SAA, Y, VVI, ET, D...   \n",
       "\n",
       "                           PUMA pre pam70 0.7 0.05 12800  \\\n",
       "0      [MEL, SA, EYL, REKL, QRDL, EA, EHVL, PSP, GGVG...   \n",
       "1      [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...   \n",
       "2      [MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...   \n",
       "3      [M, FRRL, TFA, QLL, FA, TVL, GIA, GGV, YI, FQ,...   \n",
       "4                     [M, RW, QE, MG, YI, FY, PR, KL, R]   \n",
       "...                                                  ...   \n",
       "70687  [M, L, QE, WL, AAVG, DD, YAA, VV, W, RP, EG, E...   \n",
       "70688  [EV, KGL, FK, SEN, CP, KVI, SC, EFA, HN, SNW, ...   \n",
       "70689  [MAGL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PGG,...   \n",
       "70690  [MSG, Y, SSD, RD, RG, RD, RG, FGA, PR, FGG, SR...   \n",
       "70691  [X, HG, ADA, MH, TD, PDY, SAA, Y, VVI, ET, DAE...   \n",
       "\n",
       "                           PUMA pre pam70 0.7 0.05 25600  \n",
       "0      [MEL, SA, EYL, REKL, QRDL, EA, EHVL, PSP, GGVG...  \n",
       "1      [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...  \n",
       "2      [MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...  \n",
       "3      [M, FRRL, TFA, QLL, FA, TVL, GIA, GGV, YI, FQ,...  \n",
       "4                       [M, RW, QE, MG, YI, FY, PRKL, R]  \n",
       "...                                                  ...  \n",
       "70687  [M, L, QE, WL, AAVG, DD, YAA, VV, W, RPEG, EPR...  \n",
       "70688  [EV, KGL, FK, SEN, CP, KVI, SC, EFA, HN, SNW, ...  \n",
       "70689  [MAGL, TDL, QRL, QARV, EEL, ER, WV, YG, PGG, A...  \n",
       "70690  [MSG, Y, SSD, RD, RGRD, RG, FGA, PR, FGG, SRAG...  \n",
       "70691  [X, HG, ADA, MH, TD, PDY, SAA, Y, VVI, ET, DAE...  \n",
       "\n",
       "[70692 rows x 8 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protein_sliced = df_protein_sliced.groupby('uniprot_id').sum().reset_index()\n",
    "df_protein = df_protein.set_index(['uniprot_id', 'sequence']).join(df_protein_sliced.set_index(['uniprot_id', 'sequence'])).reset_index()\n",
    "df_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>go_id</th>\n",
       "      <th>go_name</th>\n",
       "      <th>go_aspect</th>\n",
       "      <th>sequence</th>\n",
       "      <th>PUMA blosum62 0.7 0.05 6400</th>\n",
       "      <th>PUMA blosum62 0.7 0.05 12800</th>\n",
       "      <th>PUMA blosum62 0.7 0.05 25600</th>\n",
       "      <th>PUMA pre pam70 0.7 0.05 6400</th>\n",
       "      <th>PUMA pre pam70 0.7 0.05 12800</th>\n",
       "      <th>PUMA pre pam70 0.7 0.05 25600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A087X1C5</td>\n",
       "      <td>GO:0016491</td>\n",
       "      <td>oxidoreductase activity</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>MGLEALVPLAMIVAIFLLLVDLMHRHQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A087X1C5</td>\n",
       "      <td>GO:0005739</td>\n",
       "      <td>mitochondrion</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>MGLEALVPLAMIVAIFLLLVDLMHRHQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "      <td>[MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A087X296</td>\n",
       "      <td>GO:0006629</td>\n",
       "      <td>lipid metabolic process</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGIC...</td>\n",
       "      <td>[M, SR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, ...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...</td>\n",
       "      <td>[MSR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, PG...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A087X296</td>\n",
       "      <td>GO:0016491</td>\n",
       "      <td>oxidoreductase activity</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGIC...</td>\n",
       "      <td>[M, SR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, ...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...</td>\n",
       "      <td>[MSR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, PG...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A087X296</td>\n",
       "      <td>GO:0005783</td>\n",
       "      <td>endoplasmic reticulum</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGIC...</td>\n",
       "      <td>[M, SR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, ...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...</td>\n",
       "      <td>[MSR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, PG...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...</td>\n",
       "      <td>[MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141480</th>\n",
       "      <td>X6RL45</td>\n",
       "      <td>GO:0016787</td>\n",
       "      <td>hydrolase activity</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>MVRCYVEIVEKLPERRPDPATIEGCAQLKPNNYLLAWHTPFNEKGS...</td>\n",
       "      <td>[MV, RC, YV, EIV, EKL, PE, RR, PD, PA, TI, EG,...</td>\n",
       "      <td>[MV, RC, YV, EIV, EKL, PERR, PD, PA, TI, EG, C...</td>\n",
       "      <td>[MV, RC, YV, EIV, EKL, PERR, PD, PATI, EG, CA,...</td>\n",
       "      <td>[MV, RC, YV, EIV, EKL, PE, RR, PD, PA, TI, EG,...</td>\n",
       "      <td>[MV, RC, YV, EIV, EKL, PERR, PD, PA, TI, EG, C...</td>\n",
       "      <td>[MV, RC, YV, EIV, EKL, PERR, PDPA, TIEG, CA, Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141481</th>\n",
       "      <td>X6RLN4</td>\n",
       "      <td>GO:0005829</td>\n",
       "      <td>cytosol</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>EVKGLFKSENCPKVISCEFAHNSNWYITFQSDTDAQQAFKYLREEV...</td>\n",
       "      <td>[EV, KGL, FK, SEN, C, P, KVI, SC, EFA, HN, SN,...</td>\n",
       "      <td>[EV, KGL, FK, SEN, C, PKVI, SC, EFA, HN, SN, W...</td>\n",
       "      <td>[EV, KGL, FK, SEN, C, PKVI, SC, EFA, HN, SN, W...</td>\n",
       "      <td>[EV, KGL, FK, SEN, C, P, KVI, SC, EFA, HN, SNW...</td>\n",
       "      <td>[EV, KGL, FK, SEN, CP, KVI, SC, EFA, HN, SNW, ...</td>\n",
       "      <td>[EV, KGL, FK, SEN, CP, KVI, SC, EFA, HN, SNW, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141482</th>\n",
       "      <td>X6RLR1</td>\n",
       "      <td>GO:0000910</td>\n",
       "      <td>cytokinesis</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>MAGLTDLQRLQARVEELERWVYGPGGARGSRKVADGLVKVQVALGN...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QARV, EEL, ER, WV, YG, PGG,...</td>\n",
       "      <td>[MA, GL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MAGL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PGG,...</td>\n",
       "      <td>[MAGL, TDL, QRL, QARV, EEL, ER, WV, YG, PGG, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141483</th>\n",
       "      <td>X6RLR1</td>\n",
       "      <td>GO:0005730</td>\n",
       "      <td>nucleolus</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>MAGLTDLQRLQARVEELERWVYGPGGARGSRKVADGLVKVQVALGN...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QARV, EEL, ER, WV, YG, PGG,...</td>\n",
       "      <td>[MA, GL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MAGL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PGG,...</td>\n",
       "      <td>[MAGL, TDL, QRL, QARV, EEL, ER, WV, YG, PGG, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141484</th>\n",
       "      <td>X6RLR1</td>\n",
       "      <td>GO:0005829</td>\n",
       "      <td>cytosol</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>MAGLTDLQRLQARVEELERWVYGPGGARGSRKVADGLVKVQVALGN...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MA, GLT, DL, QRL, QARV, EEL, ER, WV, YG, PGG,...</td>\n",
       "      <td>[MA, GL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PG...</td>\n",
       "      <td>[MAGL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PGG,...</td>\n",
       "      <td>[MAGL, TDL, QRL, QARV, EEL, ER, WV, YG, PGG, A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141485 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uniprot_id       go_id                  go_name           go_aspect  \\\n",
       "0       A0A087X1C5  GO:0016491  oxidoreductase activity  molecular_function   \n",
       "1       A0A087X1C5  GO:0005739            mitochondrion  cellular_component   \n",
       "2       A0A087X296  GO:0006629  lipid metabolic process  biological_process   \n",
       "3       A0A087X296  GO:0016491  oxidoreductase activity  molecular_function   \n",
       "4       A0A087X296  GO:0005783    endoplasmic reticulum  cellular_component   \n",
       "...            ...         ...                      ...                 ...   \n",
       "141480      X6RL45  GO:0016787       hydrolase activity  molecular_function   \n",
       "141481      X6RLN4  GO:0005829                  cytosol  cellular_component   \n",
       "141482      X6RLR1  GO:0000910              cytokinesis  biological_process   \n",
       "141483      X6RLR1  GO:0005730                nucleolus  cellular_component   \n",
       "141484      X6RLR1  GO:0005829                  cytosol  cellular_component   \n",
       "\n",
       "                                                 sequence  \\\n",
       "0       MGLEALVPLAMIVAIFLLLVDLMHRHQRWAARYPPGPLPLPGLGNL...   \n",
       "1       MGLEALVPLAMIVAIFLLLVDLMHRHQRWAARYPPGPLPLPGLGNL...   \n",
       "2       MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGIC...   \n",
       "3       MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGIC...   \n",
       "4       MSRSLLLWFLLFLLLLPPLPVLLADPGAPTPVNPCCYYPCQHQGIC...   \n",
       "...                                                   ...   \n",
       "141480  MVRCYVEIVEKLPERRPDPATIEGCAQLKPNNYLLAWHTPFNEKGS...   \n",
       "141481  EVKGLFKSENCPKVISCEFAHNSNWYITFQSDTDAQQAFKYLREEV...   \n",
       "141482  MAGLTDLQRLQARVEELERWVYGPGGARGSRKVADGLVKVQVALGN...   \n",
       "141483  MAGLTDLQRLQARVEELERWVYGPGGARGSRKVADGLVKVQVALGN...   \n",
       "141484  MAGLTDLQRLQARVEELERWVYGPGGARGSRKVADGLVKVQVALGN...   \n",
       "\n",
       "                              PUMA blosum62 0.7 0.05 6400  \\\n",
       "0       [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "1       [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "2       [M, SR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, ...   \n",
       "3       [M, SR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, ...   \n",
       "4       [M, SR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, ...   \n",
       "...                                                   ...   \n",
       "141480  [MV, RC, YV, EIV, EKL, PE, RR, PD, PA, TI, EG,...   \n",
       "141481  [EV, KGL, FK, SEN, C, P, KVI, SC, EFA, HN, SN,...   \n",
       "141482  [MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "141483  [MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "141484  [MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "\n",
       "                             PUMA blosum62 0.7 0.05 12800  \\\n",
       "0       [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "1       [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "2       [MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...   \n",
       "3       [MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...   \n",
       "4       [MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...   \n",
       "...                                                   ...   \n",
       "141480  [MV, RC, YV, EIV, EKL, PERR, PD, PA, TI, EG, C...   \n",
       "141481  [EV, KGL, FK, SEN, C, PKVI, SC, EFA, HN, SN, W...   \n",
       "141482  [MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "141483  [MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "141484  [MA, GLT, DL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "\n",
       "                             PUMA blosum62 0.7 0.05 25600  \\\n",
       "0       [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "1       [MGL, EALV, PL, AMI, VA, IF, LLLV, DLM, HRH, Q...   \n",
       "2       [MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...   \n",
       "3       [MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...   \n",
       "4       [MSR, SLLL, WFLL, FLLLL, PPL, PVLL, AD, PGA, P...   \n",
       "...                                                   ...   \n",
       "141480  [MV, RC, YV, EIV, EKL, PERR, PD, PATI, EG, CA,...   \n",
       "141481  [EV, KGL, FK, SEN, C, PKVI, SC, EFA, HN, SN, W...   \n",
       "141482  [MA, GLT, DL, QRL, QARV, EEL, ER, WV, YG, PGG,...   \n",
       "141483  [MA, GLT, DL, QRL, QARV, EEL, ER, WV, YG, PGG,...   \n",
       "141484  [MA, GLT, DL, QRL, QARV, EEL, ER, WV, YG, PGG,...   \n",
       "\n",
       "                             PUMA pre pam70 0.7 0.05 6400  \\\n",
       "0       [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...   \n",
       "1       [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...   \n",
       "2       [MSR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, PG...   \n",
       "3       [MSR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, PG...   \n",
       "4       [MSR, SLLL, W, FLL, FLL, LL, PPL, PVLL, AD, PG...   \n",
       "...                                                   ...   \n",
       "141480  [MV, RC, YV, EIV, EKL, PE, RR, PD, PA, TI, EG,...   \n",
       "141481  [EV, KGL, FK, SEN, C, P, KVI, SC, EFA, HN, SNW...   \n",
       "141482  [MA, GL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "141483  [MA, GL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "141484  [MA, GL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PG...   \n",
       "\n",
       "                            PUMA pre pam70 0.7 0.05 12800  \\\n",
       "0       [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...   \n",
       "1       [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...   \n",
       "2       [MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...   \n",
       "3       [MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...   \n",
       "4       [MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...   \n",
       "...                                                   ...   \n",
       "141480  [MV, RC, YV, EIV, EKL, PERR, PD, PA, TI, EG, C...   \n",
       "141481  [EV, KGL, FK, SEN, CP, KVI, SC, EFA, HN, SNW, ...   \n",
       "141482  [MAGL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PGG,...   \n",
       "141483  [MAGL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PGG,...   \n",
       "141484  [MAGL, TDL, QRL, QA, RV, EEL, ER, WV, YG, PGG,...   \n",
       "\n",
       "                            PUMA pre pam70 0.7 0.05 25600  \n",
       "0       [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...  \n",
       "1       [MGL, EALV, PL, AMI, VA, IF, LLLV, DL, MH, RH,...  \n",
       "2       [MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...  \n",
       "3       [MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...  \n",
       "4       [MSR, SLLL, WFLL, FLL, LL, PPL, PVLL, AD, PGA,...  \n",
       "...                                                   ...  \n",
       "141480  [MV, RC, YV, EIV, EKL, PERR, PDPA, TIEG, CA, Q...  \n",
       "141481  [EV, KGL, FK, SEN, CP, KVI, SC, EFA, HN, SNW, ...  \n",
       "141482  [MAGL, TDL, QRL, QARV, EEL, ER, WV, YG, PGG, A...  \n",
       "141483  [MAGL, TDL, QRL, QARV, EEL, ER, WV, YG, PGG, A...  \n",
       "141484  [MAGL, TDL, QRL, QARV, EEL, ER, WV, YG, PGG, A...  \n",
       "\n",
       "[141485 rows x 11 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protein_go = pd.merge(df_protein, df_quickgo, how='inner', on='uniprot_id')[['uniprot_id', 'go_id', 'go_name', 'go_aspect']+list(df_protein.columns[1:])].reset_index(drop=True)\n",
    "df_protein_go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein unitlerini \"doküman\" formatına dönüştürme\n",
    "def create_unit_documents(df: pd.DataFrame, tokenizer_col: str, token_len_thr: int = 0) -> List[str]:\n",
    "    \"\"\"Her protein için tokenizer çıktılarını boşluklarla ayrılmış doküman formatına dönüştürür\"\"\"\n",
    "    # return df[tokenizer_col].apply(lambda units: ' '.join(units)).tolist()\n",
    "    return df[tokenizer_col].apply(lambda units: ' '.join(unit for unit in units if len(unit) >= token_len_thr)).tolist()\n",
    "\n",
    "# GO terimlerini etiketlere dönüştürme\n",
    "def create_go_labels(df: pd.DataFrame, go_col: str = 'go_id') -> List[List[str]]:\n",
    "    \"\"\"Her protein için GO terimlerini liste formatında döndürür\"\"\"\n",
    "    return df[go_col].tolist()\n",
    "\n",
    "# BERTopic modeli oluşturma\n",
    "def create_bertopic_model(documents: List[str], go_labels: List[str], token_len_thr: int = 0) -> Tuple[BERTopic, np.ndarray]:\n",
    "    \"\"\"Manuel topic modelleme için BERTopic modeli oluşturur\"\"\"\n",
    "    \n",
    "    # GO terimleri için one-hot encoding\n",
    "    lb = LabelBinarizer()\n",
    "    go_binary = lb.fit_transform(go_labels)\n",
    "    \n",
    "    # CountVectorizer ayarları - protein unit'ler için\n",
    "    vectorizer_model = CountVectorizer(\n",
    "        lowercase=False,\n",
    "        token_pattern=r\"(?u)\\b\\w{%d,}\\b\" %token_len_thr,\n",
    "        stop_words=None,  # Protein unit'lerde stop word kullanmıyoruz\n",
    "        ngram_range=(1, 1),  # Tek ve çift protein unit'leri de değerlendirelim\n",
    "        min_df=5,  # En az 5 proteinde görünen unit'leri alalım\n",
    "        max_df=0.7,  # Proteinlerin %70'inden fazlasında görünenleri çıkaralım\n",
    "    )\n",
    "    \n",
    "    # Protein unit'lerin önemi için özel TF-IDF\n",
    "    ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "    \n",
    "    # Terimlerin temsil edilmesi için model\n",
    "    representation_model = KeyBERTInspired()\n",
    "    \n",
    "    empty_embedding_model = BaseEmbedder()\n",
    "    empty_dimensionality_model = BaseDimensionalityReduction()\n",
    "    empty_cluster_model = BaseCluster()\n",
    "\n",
    "    # BERTopic model oluşturma - embedding modeli belirtmiyoruz (manuel topic modelleme)\n",
    "    topic_model = BERTopic(\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "        embedding_model=empty_embedding_model,\n",
    "        umap_model=empty_dimensionality_model,\n",
    "        hdbscan_model=empty_cluster_model,\n",
    "        # representation_model=representation_model,\n",
    "        # min_topic_size=10,  # En az 10 protein içeren topic'leri kabul edelim\n",
    "        # calculate_probabilities=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Topic'leri manuel olarak GO terimleriyle eşleştir\n",
    "    topics = np.argmax(go_binary, axis=1)\n",
    "    \n",
    "    # Eğer bir protein için hiçbir GO terimi yoksa, -1 (outlier) olarak işaretle\n",
    "    topics[np.sum(go_binary, axis=1) == 0] = -1\n",
    "    \n",
    "    # Topic isimlerini go_slim_ids değerleriyle eşleştir\n",
    "    topic_labels = {i: lb.classes_[i] for i in range(len(lb.classes_))}\n",
    "    topic_labels[-1] = \"Outlier\"  # Outlier topic'i için etiket\n",
    "    \n",
    "    # Belgeleri ve topic'leri kullanarak modeli eğit\n",
    "    topic_model.fit_transform(documents, y=topics)\n",
    "    topic_model.set_topic_labels(topic_labels)\n",
    "    \n",
    "    return topic_model, topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_smoothing_matrix(similarity_matrix, lambda_smooth=0.1):\n",
    "        \"\"\"Precompute the smoothing matrix (I + λA)\"\"\"\n",
    "        # Normalize adjacency matrix (row-wise normalization)\n",
    "        if similarity_matrix is None:\n",
    "            return None\n",
    "        \n",
    "        A = similarity_matrix.copy()\n",
    "        row_sums = np.array(A.sum(axis=1)).flatten()\n",
    "        row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "        A_norm = A / row_sums[:, np.newaxis]\n",
    "        \n",
    "        # Create smoothing matrix: (I + λA)\n",
    "        I = np.eye(A_norm.shape[0])\n",
    "        smoothing_matrix = I + lambda_smooth * A_norm\n",
    "        \n",
    "        return smoothing_matrix\n",
    "\n",
    "def apply_graph_smoothing(X, smoothing_matrix):\n",
    "    \"\"\"\n",
    "    Apply graph smoothing to document-term matrix before c-TF-IDF\n",
    "    \n",
    "    Args:\n",
    "        X: Document-term matrix (n_documents x n_features)\n",
    "        similarity_matrix: Unit similarity matrix (n_features x n_features)\n",
    "        lambda_smooth: Smoothing parameter\n",
    "        \n",
    "    Returns:\n",
    "        Smoothed document-term matrix\n",
    "    \"\"\"\n",
    "    if smoothing_matrix is None:\n",
    "        return X\n",
    "    \n",
    "    # Apply smoothing: D' = D * (I + λA)\n",
    "    if sp.issparse(X):\n",
    "        X_smoothed = X.dot(sp.csr_matrix(smoothing_matrix))\n",
    "    else:\n",
    "        X_smoothed = np.dot(X, smoothing_matrix)\n",
    "        \n",
    "    return X_smoothed\n",
    "\n",
    "\n",
    "class GraphAwareCountVectorizer(CountVectorizer):\n",
    "    \"\"\"CountVectorizer that applies graph smoothing to the resulting matrix\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 similarity_matrix=None,\n",
    "                 lambda_smooth=0.1,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.lambda_smooth = lambda_smooth\n",
    "        self.similarity_matrix = similarity_matrix\n",
    "        self.smoothing_matrix = None\n",
    "    \n",
    "    def fit_transform(self, raw_documents, y=None):\n",
    "        \"\"\"Fit and transform with graph smoothing\"\"\"\n",
    "        X = super().fit_transform(raw_documents, y)\n",
    "\n",
    "        self.smoothing_matrix = compute_smoothing_matrix(self.similarity_matrix, self.lambda_smooth)\n",
    "        \n",
    "        # Apply graph smoothing if similarity matrix is available\n",
    "        if self.smoothing_matrix is not None:\n",
    "            # print('fit_transform', X.shape, self.smoothing_matrix.shape)\n",
    "            X = apply_graph_smoothing(X, self.smoothing_matrix)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def transform(self, raw_documents):\n",
    "        \"\"\"Transform with graph smoothing\"\"\"\n",
    "        X = super().transform(raw_documents)\n",
    "        # print('transform', X.shape, self.smoothing_matrix.shape)\n",
    "        \n",
    "        # Apply graph smoothing if similarity matrix is available\n",
    "        if self.smoothing_matrix is not None:\n",
    "            X = apply_graph_smoothing(X, self.smoothing_matrix)\n",
    "            \n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "def build_unit_similarity_matrix(unit_relationships: Dict[str, Dict], \n",
    "                                vocabulary: List[str],\n",
    "                                alpha: float = 1.0, \n",
    "                                beta: float = 0.5,\n",
    "                                theta: float = 0.7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build adjacency matrix for protein unit relationships\n",
    "    \n",
    "    Args:\n",
    "        unit_relationships: Dictionary containing unit relationships\n",
    "            Expected format:\n",
    "            {\n",
    "                'hierarchical': {\n",
    "                    'parent_unit': ['child1', 'child2', ...],\n",
    "                    ...\n",
    "                },\n",
    "                'mutational': {\n",
    "                    'parent1': ['child1', 'child2', ...],\n",
    "                    'parent2': ['child1', 'child2', ...],\n",
    "                    ...\n",
    "                }\n",
    "            }\n",
    "        vocabulary: List of all protein units (vocabulary from CountVectorizer)\n",
    "        alpha: Weight for merge parent-child relationships\n",
    "        beta: Weight for sibling relationships\n",
    "        theta: Weight for mutation parent-child relationships\n",
    "        \n",
    "    Returns:\n",
    "        Adjacency matrix (n_units x n_units)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create unit to index mapping\n",
    "    unit_to_idx = {unit: idx for idx, unit in enumerate(vocabulary)}\n",
    "    n_units = len(vocabulary)\n",
    "    \n",
    "    # Initialize adjacency matrix\n",
    "    A = np.zeros((n_units, n_units))\n",
    "    \n",
    "    # Add hierarchical relationships (parent-child)\n",
    "    if 'hierarchical' in unit_relationships:\n",
    "        for parent, children in unit_relationships['hierarchical'].items():\n",
    "            if parent in unit_to_idx:\n",
    "                parent_idx = unit_to_idx[parent]\n",
    "                for child in children:\n",
    "                    if child in unit_to_idx:\n",
    "                        child_idx = unit_to_idx[child]\n",
    "                        # Bidirectional parent-child relationship\n",
    "                        A[parent_idx, child_idx] = alpha\n",
    "                        A[child_idx, parent_idx] = alpha\n",
    "    \n",
    "    # Add mutational relationships (family-based)\n",
    "    if 'mutational' in unit_relationships:\n",
    "        for parent, children in unit_relationships['mutational'].items():\n",
    "            if parent in unit_to_idx:\n",
    "                parent_idx = unit_to_idx[parent]\n",
    "                for i in range(len(children)):\n",
    "                    if children[i] in unit_to_idx:\n",
    "                        child_i_idx = unit_to_idx[children[i]]\n",
    "                        # Parent-child relationship\n",
    "                        A[parent_idx, child_i_idx] = theta\n",
    "                        A[child_i_idx, parent_idx] = theta\n",
    "                        for j in range(i+1, len(children)):\n",
    "                            if children[j] in unit_to_idx:\n",
    "                                child_j_idx = unit_to_idx[children[j]]\n",
    "                                # Sibling relationship\n",
    "                                A[child_i_idx, child_j_idx] = beta\n",
    "                                A[child_j_idx, child_i_idx] = beta\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "def create_graph_aware_bertopic_model(documents: List[str], \n",
    "                                    go_labels: List[str],\n",
    "                                    unit_relationships: Optional[Dict[str, Dict]] = None,\n",
    "                                    token_len_thr: int = 0,\n",
    "                                    lambda_smooth: float = 0.1,\n",
    "                                    alpha: float = 1.0,\n",
    "                                    beta: float = 0.5,\n",
    "                                    theta: float = 0.7) -> Tuple[BERTopic, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create Graph-Aware BERTopic model for protein analysis\n",
    "    \n",
    "    Args:\n",
    "        documents: List of protein sequences (tokenized with protein units)\n",
    "        go_labels: List of GO-slim labels for each protein\n",
    "        unit_relationships: Dictionary containing unit relationships (hierarchical & mutational)\n",
    "        token_len_thr: Minimum token length threshold\n",
    "        lambda_smooth: Graph smoothing parameter\n",
    "        alpha: Weight for parent-child relationships\n",
    "        beta: Weight for sibling relationships\n",
    "        theta: Weight for mutation parent-child relationships\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (BERTopic model, topics array, similarity matrix)\n",
    "    \"\"\"\n",
    "    \n",
    "    # GO terms için one-hot encoding\n",
    "    lb = LabelBinarizer()\n",
    "    go_binary = lb.fit_transform(go_labels)\n",
    "    \n",
    "    # CountVectorizer ayarları - protein units için\n",
    "    temp_vectorizer = CountVectorizer(\n",
    "        lowercase=False,\n",
    "        token_pattern=r\"(?u)\\b\\w{%d,}\\b\" % token_len_thr,\n",
    "        stop_words=None,\n",
    "        ngram_range=(1, 1),\n",
    "        min_df=5,\n",
    "        max_df=0.7,\n",
    "    )\n",
    "    \n",
    "    temp_vectorizer.fit(documents)\n",
    "    vocabulary = temp_vectorizer.get_feature_names_out().tolist()\n",
    "\n",
    "    # Build unit similarity matrix\n",
    "    similarity_matrix = None\n",
    "    if unit_relationships is not None:\n",
    "        similarity_matrix = build_unit_similarity_matrix(\n",
    "            unit_relationships=unit_relationships,\n",
    "            vocabulary=vocabulary,\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            theta=theta\n",
    "        )\n",
    "        print(f\"Built similarity matrix with shape: {similarity_matrix.shape}\")\n",
    "        print(f\"Non-zero edges: {np.sum(similarity_matrix > 0)}\")\n",
    "    \n",
    "    # Create graph-aware CountVectorizer\n",
    "    vectorizer_model = GraphAwareCountVectorizer(\n",
    "        similarity_matrix=similarity_matrix,\n",
    "        lambda_smooth=lambda_smooth,\n",
    "        lowercase=False,\n",
    "        token_pattern=r\"(?u)\\b\\w{%d,}\\b\" % token_len_thr,\n",
    "        stop_words=None,\n",
    "        ngram_range=(1, 1),\n",
    "        min_df=5,\n",
    "        max_df=0.7,\n",
    "        vocabulary=vocabulary  # Use the same vocabulary\n",
    "    )\n",
    "    \n",
    "    # Standard c-TF-IDF model (no need for custom one now)\n",
    "    ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "    \n",
    "    # Representation model\n",
    "    representation_model = KeyBERTInspired()\n",
    "    \n",
    "    # Empty models for manual topic assignment\n",
    "    empty_embedding_model = BaseEmbedder()\n",
    "    empty_dimensionality_model = BaseDimensionalityReduction()\n",
    "    empty_cluster_model = BaseCluster()\n",
    "    \n",
    "    # BERTopic model with graph-aware c-TF-IDF\n",
    "    topic_model = BERTopic(\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        ctfidf_model=ctfidf_model,\n",
    "        embedding_model=empty_embedding_model,\n",
    "        umap_model=empty_dimensionality_model,\n",
    "        hdbscan_model=empty_cluster_model,\n",
    "        # representation_model=representation_model,\n",
    "        # min_topic_size=10,  # En az 10 protein içeren topic'leri kabul edelim\n",
    "        # calculate_probabilities=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Manual topic assignment based on GO terms\n",
    "    topics = np.argmax(go_binary, axis=1)\n",
    "    \n",
    "    # Mark proteins without GO terms as outliers\n",
    "    topics[np.sum(go_binary, axis=1) == 0] = -1\n",
    "    \n",
    "    # Create topic labels\n",
    "    topic_labels = {i: lb.classes_[i] for i in range(len(lb.classes_))}\n",
    "    topic_labels[-1] = \"Outlier\"\n",
    "    \n",
    "    # Train the model\n",
    "    topic_model.fit_transform(documents, y=topics)\n",
    "    topic_model.set_topic_labels(topic_labels)\n",
    "    \n",
    "    print(f\"Model trained with {len(set(topics))} topics\")\n",
    "    print(f\"Graph smoothing parameter λ = {lambda_smooth}\")\n",
    "    \n",
    "    return topic_model, topics, similarity_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    # Tüm benzersiz UniProt ID'leri al\n",
    "    unique_uniprot_ids = df[\"uniprot_id\"].unique().tolist()\n",
    "    random.shuffle(unique_uniprot_ids)\n",
    "\n",
    "    # ID'lerin %80-%20 şeklinde split edilmesi\n",
    "    train_ids, test_ids = train_test_split(unique_uniprot_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Verileri splitlere ayır\n",
    "    df_train = df[df[\"uniprot_id\"].isin(train_ids)].copy()\n",
    "    df_test = df[df[\"uniprot_id\"].isin(test_ids)].copy()\n",
    "\n",
    "    # GO dağılımlarını kontrol et\n",
    "    def go_dist(data):\n",
    "        return data['go_id'].value_counts(normalize=True)\n",
    "\n",
    "    train_dist = go_dist(df_train)\n",
    "    test_dist = go_dist(df_test)\n",
    "\n",
    "    # Dağılım farklarını görmek için karşılaştıralım\n",
    "    distribution_df = pd.DataFrame({\n",
    "        \"train_ratio\": train_dist,\n",
    "        \"test_ratio\": test_dist\n",
    "    }).fillna(0)\n",
    "\n",
    "    distribution_df[\"difference\"] = abs(distribution_df[\"train_ratio\"] - distribution_df[\"test_ratio\"])\n",
    "\n",
    "    # Gerekirse tolerans üstü farkları göster\n",
    "    print(distribution_df.sort_values(\"difference\", ascending=False).head(5))\n",
    "\n",
    "    return df_train.reset_index(drop=True), df_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_go_term_representations(df_test: pd.DataFrame, topic_model: BERTopic, tokenizer_col: str, go_col: str = 'go_name') -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluates the learned GO term representations on the test set using various metrics.\n",
    "\n",
    "    Args:\n",
    "        df_test: The test dataframe containing protein sequences and their true GO terms.\n",
    "        topic_model: The trained BERTopic model.\n",
    "        tokenizer_col: The name of the column in df_test with the tokenized sequences.\n",
    "        go_col: The name of the column in df_test with the true GO term labels.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the evaluation results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Step 1: Pre-process topic representations for faster lookup ---\n",
    "    # Create a mapping from GO name to a list of its representative (unit, score) tuples.\n",
    "    go_term_representations = {}\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    \n",
    "    # BERTopic might have a different internal topic ID than the label index.\n",
    "    # We need to map the topic ID to the GO name (custom label).\n",
    "    topic_id_to_go_name = {row.Topic: row.CustomName for _, row in topic_info.iterrows()}\n",
    "\n",
    "    for topic_id, go_name in topic_id_to_go_name.items():\n",
    "        if topic_id == -1:  # Skip outlier topic\n",
    "            continue\n",
    "        \n",
    "        # Get the top 10 representative units and their scores for the current topic\n",
    "        representation = topic_model.get_topic(topic_id)\n",
    "        if representation:\n",
    "            go_term_representations[go_name] = {unit: score for unit, score in representation}\n",
    "\n",
    "    # --- Step 2: Iterate through the test set and evaluate ---\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    reciprocal_ranks = []\n",
    "    \n",
    "    # Group by protein to handle multiple GO terms per protein if necessary,\n",
    "    # though the current setup seems to be one primary GO term per row.\n",
    "    test_proteins = df_test.groupby('uniprot_id')\n",
    "\n",
    "    for uniprot_id, protein_data in tqdm(test_proteins, desc=\"Evaluating Test Set\"):\n",
    "        # Use the first row's data for simplicity, assuming one main GO term per protein.\n",
    "        true_go_name = protein_data.iloc[0][go_col]\n",
    "        \n",
    "        # The tokenized sequence for this protein. Use a set for O(1) lookups.\n",
    "        tokenized_sequence = set(protein_data.iloc[0][tokenizer_col])\n",
    "        \n",
    "        if not tokenized_sequence:\n",
    "            continue\n",
    "\n",
    "        # --- Step 3: Score all possible GO terms for the current protein ---\n",
    "        go_scores = {}\n",
    "        for go_name, representation in go_term_representations.items():\n",
    "            score = 0\n",
    "            # Sum the scores of representative units that are present in the protein's sequence\n",
    "            for unit, unit_score in representation.items():\n",
    "                if unit in tokenized_sequence:\n",
    "                    score += unit_score\n",
    "            go_scores[go_name] = score\n",
    "            \n",
    "        if not go_scores:\n",
    "            continue\n",
    "\n",
    "        # Sort GO terms by their calculated score in descending order\n",
    "        sorted_go_terms = sorted(go_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "        # The top prediction is the GO term with the highest score\n",
    "        predicted_go_name = sorted_go_terms[0][0]\n",
    "        \n",
    "        y_true.append(true_go_name)\n",
    "        y_pred.append(predicted_go_name)\n",
    "        \n",
    "        # --- Step 4: Calculate rank of the true GO term for MRR ---\n",
    "        rank = -1\n",
    "        for i, (go_name, score) in enumerate(sorted_go_terms):\n",
    "            if go_name == true_go_name:\n",
    "                rank = i + 1\n",
    "                break\n",
    "        \n",
    "        if rank != -1:\n",
    "            reciprocal_ranks.append(1.0 / rank)\n",
    "        else:\n",
    "            reciprocal_ranks.append(0.0) # True GO term was not found in the ranked list\n",
    "\n",
    "    # --- Step 5: Calculate and compile final metrics ---\n",
    "    results = {}\n",
    "\n",
    "    # --- Metric: Top-k Accuracy ---\n",
    "    # Calculates the percentage of times the true GO term is in the top k predictions.\n",
    "    top_k_accuracies = {}\n",
    "    for k in [1, 3, 5, 10]:\n",
    "        correct_predictions = 0\n",
    "        for i in range(len(y_true)):\n",
    "            # Re-calculate sorted list for each protein to check top-k\n",
    "            # This is slightly redundant but clear. Could be optimized by storing all sorted lists.\n",
    "            protein_data = df_test[df_test['uniprot_id'] == df_test['uniprot_id'].unique()[i]]\n",
    "            tokenized_sequence = set(protein_data.iloc[0][tokenizer_col])\n",
    "            go_scores = {go: sum(score for unit, score in go_term_representations.get(go, {}).items() if unit in tokenized_sequence) for go in go_term_representations}\n",
    "            sorted_go_terms = [item[0] for item in sorted(go_scores.items(), key=lambda item: item[1], reverse=True)]\n",
    "            \n",
    "            if y_true[i] in sorted_go_terms[:k]:\n",
    "                correct_predictions += 1\n",
    "        top_k_accuracies[f'accuracy_at_{k}'] = correct_predictions / len(y_true) if y_true else 0\n",
    "    \n",
    "    results['top_k_accuracy'] = top_k_accuracies\n",
    "    \n",
    "    # --- Metric: Mean Reciprocal Rank (MRR) ---\n",
    "    # The average of the reciprocal ranks of the correct GO term.\n",
    "    # A value of 1 means the correct answer is always the first prediction.\n",
    "    # A value of 0.5 means the correct answer is, on average, the second prediction.\n",
    "    results['mean_reciprocal_rank'] = np.mean(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "\n",
    "    # --- Metric: Classification Report (Precision, Recall, F1-Score) ---\n",
    "    # Based on the top-1 prediction (the GO term with the highest weighted score).\n",
    "    # Precision: Of all proteins predicted to have a certain GO term, how many were correct?\n",
    "    # Recall: Of all proteins that truly have a certain GO term, how many did we identify?\n",
    "    # F1-Score: The harmonic mean of Precision and Recall.\n",
    "    # Accuracy: Overall, what fraction of predictions were correct?\n",
    "    if y_true and y_pred:\n",
    "        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "        results['classification_report'] = {\n",
    "            'accuracy': report['accuracy'],\n",
    "            'macro_avg': report['macro avg'],\n",
    "            'weighted_avg': report['weighted avg']\n",
    "        }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_go_term_representations(df_test: pd.DataFrame, topic_model: BERTopic, tokenizer_col: str, go_col: str = 'go_name') -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluates the learned GO term representations on the test set using various metrics.\n",
    "    This version is optimized for speed and includes per-GO-term metrics and frequency-based scoring.\n",
    "\n",
    "    Args:\n",
    "        df_test: The test dataframe containing protein sequences and their true GO terms.\n",
    "        topic_model: The trained BERTopic model.\n",
    "        tokenizer_col: The name of the column in df_test with the tokenized sequences.\n",
    "        go_col: The name of the column in df_test with the true GO term labels.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the evaluation results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Step 1: Pre-process topic representations for faster lookup ---\n",
    "    go_term_representations = {}\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    topic_id_to_go_name = {row.Topic: row.CustomName for _, row in topic_info.iterrows()}\n",
    "\n",
    "    for topic_id, go_name in topic_id_to_go_name.items():\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "        representation = topic_model.get_topic(topic_id)\n",
    "        if representation:\n",
    "            go_term_representations[go_name] = {unit: score for unit, score in representation}\n",
    "\n",
    "    # --- Step 2: Iterate through the test set to get predictions and scores ---\n",
    "    y_true = []\n",
    "    all_sorted_predictions = []\n",
    "    reciprocal_ranks = []\n",
    "    \n",
    "    test_proteins = df_test.groupby('uniprot_id')\n",
    "\n",
    "    for uniprot_id, protein_data in tqdm(test_proteins, desc=\"Evaluating Test Set\"):\n",
    "        true_go_name = protein_data.iloc[0][go_col]\n",
    "        \n",
    "        # Use a Counter to get frequencies of each unit for the new scoring metric.\n",
    "        tokenized_sequence = protein_data.iloc[0][tokenizer_col]\n",
    "        if not tokenized_sequence:\n",
    "            continue\n",
    "        token_counts = Counter(tokenized_sequence)\n",
    "\n",
    "        # --- Step 3: Score all possible GO terms for the current protein ---\n",
    "        go_scores = {}\n",
    "        for go_name, representation in go_term_representations.items():\n",
    "            # Sum the scores of representative units that are present in the protein's sequence\n",
    "            score = sum(unit_score for unit, unit_score in representation.items() if unit in tokenized_sequence)\n",
    "            # New Metric: Score is the sum of (unit_score * unit_frequency_in_protein)\n",
    "            # score = sum(unit_score * token_counts.get(unit, 0) for unit, unit_score in representation.items())\n",
    "            \n",
    "            go_scores[go_name] = score\n",
    "            \n",
    "        if not go_scores:\n",
    "            continue\n",
    "\n",
    "        # Sort GO terms by their calculated score in descending order\n",
    "        sorted_go_terms = sorted(go_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "        \n",
    "        # Store the full sorted list of predictions for efficient top-k calculation later\n",
    "        sorted_prediction_names = [go_name for go_name, score in sorted_go_terms]\n",
    "        all_sorted_predictions.append(sorted_prediction_names)\n",
    "        y_true.append(true_go_name)\n",
    "        \n",
    "        # --- Step 4: Calculate rank of the true GO term for MRR ---\n",
    "        try:\n",
    "            rank = sorted_prediction_names.index(true_go_name) + 1\n",
    "            reciprocal_ranks.append(1.0 / rank)\n",
    "        except ValueError:\n",
    "            # The true GO term was not in the list of predictions\n",
    "            reciprocal_ranks.append(0.0)\n",
    "\n",
    "    # --- Step 5: Calculate and compile final metrics ---\n",
    "    results = {}\n",
    "    \n",
    "    if not y_true:\n",
    "        return {\"error\": \"No test data to evaluate.\"}\n",
    "\n",
    "    # --- Metric: Top-k Accuracy (Optimized) ---\n",
    "    # Calculates the percentage of times the true GO term is in the top k predictions.\n",
    "    top_k_accuracies = {}\n",
    "    for k in [1, 3, 5, 10]:\n",
    "        correct_predictions = sum(1 for i, true_label in enumerate(y_true) if true_label in all_sorted_predictions[i][:k])\n",
    "        top_k_accuracies[f'accuracy_at_{k}'] = correct_predictions / len(y_true)\n",
    "    \n",
    "    results['top_k_accuracy'] = top_k_accuracies\n",
    "    \n",
    "    # --- Metric: Mean Reciprocal Rank (MRR) ---\n",
    "    # The average of the reciprocal ranks of the correct GO term.\n",
    "    results['mean_reciprocal_rank'] = np.mean(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "\n",
    "    # --- Metric: Classification Report (Precision, Recall, F1-Score) ---\n",
    "    # Based on the top-1 prediction (the GO term with the highest weighted score).\n",
    "    y_pred = [preds[0] if preds else None for preds in all_sorted_predictions]\n",
    "    \n",
    "    # Filter out None predictions if any protein had no scoreable GO terms\n",
    "    valid_indices = [i for i, p in enumerate(y_pred) if p is not None]\n",
    "    y_true_filtered = [y_true[i] for i in valid_indices]\n",
    "    y_pred_filtered = [y_pred[i] for i in valid_indices]\n",
    "\n",
    "    if y_true_filtered and y_pred_filtered:\n",
    "        # Get all labels present in either true or predicted sets for the report\n",
    "        labels = sorted(list(set(y_true_filtered) | set(y_pred_filtered)))\n",
    "        report = classification_report(y_true_filtered, y_pred_filtered, labels=labels, output_dict=True, zero_division=0)\n",
    "        \n",
    "        # Separate overall metrics from per-GO-term metrics\n",
    "        results['classification_summary'] = {\n",
    "            'accuracy': report['accuracy'],\n",
    "            'macro_avg': report['macro avg'],\n",
    "            'weighted_avg': report['weighted avg']\n",
    "        }\n",
    "        \n",
    "        # --- New: Per-GO-Term Metrics ---\n",
    "        # Detailed precision, recall, f1-score for each individual GO term.\n",
    "        per_go_term_metrics = {label: report[label] for label in labels if label in report}\n",
    "        results['per_go_term_metrics'] = per_go_term_metrics\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_go_term_representations_multilabel(df_test: pd.DataFrame, topic_model: BERTopic, tokenizer_col: str, go_col: str = 'go_name') -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluates GO term representations considering all GO terms for each protein (multi-label evaluation).\n",
    "    Includes multi-label accuracy@k, precision@k, recall@k, and a full classification report.\n",
    "\n",
    "    Args:\n",
    "        df_test: The test dataframe with all GO term associations for each protein.\n",
    "        topic_model: The trained BERTopic model.\n",
    "        tokenizer_col: The name of the column with tokenized sequences.\n",
    "        go_col: The name of the column with GO term labels.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with comprehensive multi-label evaluation results.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Step 1: Pre-process topic representations ---\n",
    "    go_term_representations = {}\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    topic_id_to_go_name = {row.Topic: row.CustomName for _, row in topic_info.iterrows()}\n",
    "\n",
    "    for topic_id, go_name in topic_id_to_go_name.items():\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "        representation = topic_model.get_topic(topic_id)\n",
    "        if representation:\n",
    "            go_term_representations[go_name] = {unit: score for unit, score in representation}\n",
    "\n",
    "    # --- Step 2: Get predictions for each protein in the test set ---\n",
    "    y_true_sets = []\n",
    "    all_sorted_predictions = []\n",
    "    \n",
    "    test_proteins = df_test.groupby('uniprot_id')\n",
    "\n",
    "    for uniprot_id, protein_data in tqdm(test_proteins, desc=\"Evaluating Test Set (Multi-Label)\"):\n",
    "        true_go_names = set(protein_data[go_col].tolist())\n",
    "        tokenized_sequence = protein_data.iloc[0][tokenizer_col]\n",
    "        if not tokenized_sequence:\n",
    "            continue\n",
    "        token_counts = Counter(tokenized_sequence)\n",
    "\n",
    "        # Sum the scores of representative units that are present in the protein's sequence\n",
    "        go_scores = {go_name: sum(unit_score for unit, unit_score in representation.items() if unit in tokenized_sequence) for go_name, representation in go_term_representations.items()}\n",
    "        # New Metric: Score is the sum of (unit_score * unit_frequency_in_protein)\n",
    "        # go_scores = {go_name: sum(unit_score * token_counts.get(unit, 0) for unit, unit_score in representation.items()) for go_name, representation in go_term_representations.items()}\n",
    "        \n",
    "        if not go_scores:\n",
    "            continue\n",
    "\n",
    "        sorted_prediction_names = [go_name for go_name, score in sorted(go_scores.items(), key=lambda item: item[1], reverse=True)]\n",
    "        \n",
    "        all_sorted_predictions.append(sorted_prediction_names)\n",
    "        y_true_sets.append(true_go_names)\n",
    "\n",
    "    # --- Step 3: Calculate and compile multi-label metrics ---\n",
    "    results = {}\n",
    "    if not y_true_sets:\n",
    "        return {\"error\": \"No test data to evaluate.\"}\n",
    "\n",
    "    # --- Metric: Mean Reciprocal Rank (MRR) ---\n",
    "    reciprocal_ranks = []\n",
    "    for i, true_set in enumerate(y_true_sets):\n",
    "        rank = next((r + 1 for r, p in enumerate(all_sorted_predictions[i]) if p in true_set), 0)\n",
    "        reciprocal_ranks.append(1.0 / rank if rank > 0 else 0.0)\n",
    "    results['mean_reciprocal_rank'] = np.mean(reciprocal_ranks) if reciprocal_ranks else 0\n",
    "\n",
    "    # --- Metrics: Accuracy@k, Precision@k, and Recall@k ---\n",
    "    accuracy_at_k = {}\n",
    "    precision_at_k = {}\n",
    "    recall_at_k = {}\n",
    "    \n",
    "    for k in [1, 3, 5, 10]:\n",
    "        acc_at_k_scores = []\n",
    "        p_at_k_scores = []\n",
    "        r_at_k_scores = []\n",
    "        for i, true_set in enumerate(y_true_sets):\n",
    "            if not true_set: continue\n",
    "            \n",
    "            pred_set_at_k = set(all_sorted_predictions[i][:k])\n",
    "            hits = len(true_set.intersection(pred_set_at_k))\n",
    "            \n",
    "            # Accuracy@k: 1 if there is at least one hit, 0 otherwise.\n",
    "            acc_at_k_scores.append(1.0 if hits > 0 else 0.0)\n",
    "            p_at_k_scores.append(hits / k)\n",
    "            r_at_k_scores.append(hits / len(true_set))\n",
    "            \n",
    "        accuracy_at_k[f'accuracy_at_{k}'] = np.mean(acc_at_k_scores) if acc_at_k_scores else 0\n",
    "        precision_at_k[f'precision_at_{k}'] = np.mean(p_at_k_scores) if p_at_k_scores else 0\n",
    "        recall_at_k[f'recall_at_{k}'] = np.mean(r_at_k_scores) if r_at_k_scores else 0\n",
    "\n",
    "    results['accuracy_at_k'] = accuracy_at_k\n",
    "    results['precision_at_k'] = precision_at_k\n",
    "    results['recall_at_k'] = recall_at_k\n",
    "\n",
    "    # --- Metric: Multi-Label Classification Report ---\n",
    "    # To create a report, we must convert the ranking into a binary prediction.\n",
    "    # Strategy: For each sample, predict the top N labels, where N is the number of true labels for that sample.\n",
    "    all_labels = sorted(list(go_term_representations.keys()))\n",
    "    mlb = MultiLabelBinarizer(classes=all_labels)\n",
    "    \n",
    "    y_true_binary = mlb.fit_transform(y_true_sets)\n",
    "    y_pred_binary = []\n",
    "\n",
    "    for i, true_set in enumerate(y_true_sets):\n",
    "        # Predict top k labels where k is the number of true labels\n",
    "        k = len(true_set)\n",
    "        if k == 0: continue\n",
    "        top_k_preds = all_sorted_predictions[i][:k]\n",
    "        y_pred_binary.append(mlb.transform([top_k_preds])[0])\n",
    "\n",
    "    if y_pred_binary:\n",
    "        y_pred_binary = np.array(y_pred_binary)\n",
    "        # We need to align y_true_binary with the proteins we actually made predictions for\n",
    "        y_true_binary_filtered = [y_true_binary[i] for i, ts in enumerate(y_true_sets) if len(ts) > 0]\n",
    "\n",
    "        report = classification_report(\n",
    "            y_true_binary_filtered, \n",
    "            y_pred_binary, \n",
    "            target_names=all_labels, \n",
    "            output_dict=True, \n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        results['classification_summary'] = {\n",
    "            'micro_avg': report['micro avg'],\n",
    "            'macro_avg': report['macro avg'],\n",
    "            'weighted_avg': report['weighted avg'],\n",
    "            'samples_avg': report['samples avg']\n",
    "        }\n",
    "        \n",
    "        per_go_term_metrics = {label: report[label] for label in all_labels if label in report}\n",
    "        results['per_go_term_metrics'] = per_go_term_metrics\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            train_ratio  test_ratio  difference\n",
      "go_id                                          \n",
      "GO:0005829     0.114518    0.118779    0.004261\n",
      "GO:0005576     0.071755    0.074699    0.002944\n",
      "GO:0005634     0.173395    0.176036    0.002641\n",
      "GO:0005654     0.101733    0.099346    0.002388\n",
      "GO:0005929     0.018766    0.017063    0.001702\n",
      "Tokenizer kullanılıyor: PUMA blosum62 0.7 0.05 12800\n"
     ]
    }
   ],
   "source": [
    "# df = df_protein_go.copy()\n",
    "df = df_protein_go[df_protein_go['go_aspect'] == 'cellular_component'].reset_index(drop=True).copy()\n",
    "df_train, df_test = split_data(df)\n",
    "\n",
    "tokenizer_col = 'PUMA blosum62 0.7 0.05 12800'\n",
    "go_col = 'go_name'\n",
    "token_len_thr = 0\n",
    "\n",
    "unit_relationships = {'hierarchical': {}, 'mutational': {}}\n",
    "for unit, lineage in vocab_lineage_list[tokenizer_col].items():\n",
    "    if len(lineage['child_pair']) > 0:\n",
    "        unit_relationships['hierarchical'][unit] = lineage['child_pair']\n",
    "    if len(lineage['child_mutation']) > 0:\n",
    "        unit_relationships['mutational'][unit] = lineage['child_mutation']\n",
    "\n",
    "print(f\"Tokenizer kullanılıyor: {tokenizer_col}\")\n",
    "documents = create_unit_documents(df_train, tokenizer_col, token_len_thr)\n",
    "go_labels = create_go_labels(df_train, go_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 00:17:55,908 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "2025-07-01 00:17:55,909 - BERTopic - Embedding - Completed ✓\n",
      "2025-07-01 00:17:55,910 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-07-01 00:17:55,910 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-07-01 00:17:55,911 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-07-01 00:17:55,913 - BERTopic - Cluster - Completed ✓\n",
      "2025-07-01 00:17:55,919 - BERTopic - Representation - Fine-tuning topics using representation models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTopic modeli oluşturuluyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 00:17:56,559 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "print(\"BERTopic modeli oluşturuluyor...\")\n",
    "topic_model, topics = create_bertopic_model(documents, go_labels, token_len_thr=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 01:09:53,532 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "2025-07-01 01:09:53,534 - BERTopic - Embedding - Completed ✓\n",
      "2025-07-01 01:09:53,534 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-07-01 01:09:53,534 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-07-01 01:09:53,535 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-07-01 01:09:53,538 - BERTopic - Cluster - Completed ✓\n",
      "2025-07-01 01:09:53,543 - BERTopic - Representation - Fine-tuning topics using representation models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built similarity matrix with shape: (8155, 8155)\n",
      "Non-zero edges: 191212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 01:09:54,720 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with 25 topics\n",
      "Graph smoothing parameter λ = 0.7\n"
     ]
    }
   ],
   "source": [
    "# print(\"BERTopic modeli oluşturuluyor...\")\n",
    "topic_model, topics, similarity_matrix = create_graph_aware_bertopic_model(documents, go_labels, unit_relationships, token_len_thr=4, lambda_smooth=0.7, alpha=1, beta=0.5, theta=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set: 100%|██████████| 5886/5886 [00:01<00:00, 3200.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GO Term Representation Evaluation Results ---\n",
      "{\n",
      "  \"top_k_accuracy\": {\n",
      "    \"accuracy_at_1\": 0.03856608902480462,\n",
      "    \"accuracy_at_3\": 0.08341828066598708,\n",
      "    \"accuracy_at_5\": 0.13302752293577982,\n",
      "    \"accuracy_at_10\": 0.36493374108053006\n",
      "  },\n",
      "  \"mean_reciprocal_rank\": 0.13190339625620615,\n",
      "  \"classification_summary\": {\n",
      "    \"accuracy\": 0.03856608902480462,\n",
      "    \"macro_avg\": {\n",
      "      \"precision\": 0.04505983249060523,\n",
      "      \"recall\": 0.05537094435395813,\n",
      "      \"f1-score\": 0.025695922545264496,\n",
      "      \"support\": 5886.0\n",
      "    },\n",
      "    \"weighted_avg\": {\n",
      "      \"precision\": 0.14757174649226928,\n",
      "      \"recall\": 0.03856608902480462,\n",
      "      \"f1-score\": 0.039826980239771714,\n",
      "      \"support\": 5886.0\n",
      "    }\n",
      "  },\n",
      "  \"per_go_term_metrics\": {\n",
      "    \"Golgi apparatus\": {\n",
      "      \"precision\": 0.027186761229314422,\n",
      "      \"recall\": 0.39655172413793105,\n",
      "      \"f1-score\": 0.05088495575221239,\n",
      "      \"support\": 174.0\n",
      "    },\n",
      "    \"chromosome\": {\n",
      "      \"precision\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"f1-score\": 0.0,\n",
      "      \"support\": 30.0\n",
      "    },\n",
      "    \"cilium\": {\n",
      "      \"precision\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"f1-score\": 0.0,\n",
      "      \"support\": 72.0\n",
      "    },\n",
      "    \"cytoplasmic vesicle\": {\n",
      "      \"precision\": 0.013477088948787063,\n",
      "      \"recall\": 0.042735042735042736,\n",
      "      \"f1-score\": 0.020491803278688523,\n",
      "      \"support\": 117.0\n",
      "    },\n",
      "    \"cytoskeleton\": {\n",
      "      \"precision\": 0.009708737864077669,\n",
      "      \"recall\": 0.004016064257028112,\n",
      "      \"f1-score\": 0.005681818181818182,\n",
      "      \"support\": 249.0\n",
      "    },\n",
      "    \"cytosol\": {\n",
      "      \"precision\": 0.08173076923076923,\n",
      "      \"recall\": 0.042606516290726815,\n",
      "      \"f1-score\": 0.05601317957166392,\n",
      "      \"support\": 399.0\n",
      "    },\n",
      "    \"endoplasmic reticulum\": {\n",
      "      \"precision\": 0.15060240963855423,\n",
      "      \"recall\": 0.0764525993883792,\n",
      "      \"f1-score\": 0.10141987829614604,\n",
      "      \"support\": 327.0\n",
      "    },\n",
      "    \"endosome\": {\n",
      "      \"precision\": 0.019230769230769232,\n",
      "      \"recall\": 0.012903225806451613,\n",
      "      \"f1-score\": 0.015444015444015444,\n",
      "      \"support\": 155.0\n",
      "    },\n",
      "    \"extracellular matrix\": {\n",
      "      \"precision\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"f1-score\": 0.0,\n",
      "      \"support\": 13.0\n",
      "    },\n",
      "    \"extracellular region\": {\n",
      "      \"precision\": 0.11578947368421053,\n",
      "      \"recall\": 0.014705882352941176,\n",
      "      \"f1-score\": 0.02609727164887307,\n",
      "      \"support\": 748.0\n",
      "    },\n",
      "    \"extracellular space\": {\n",
      "      \"precision\": 0.043478260869565216,\n",
      "      \"recall\": 0.05714285714285714,\n",
      "      \"f1-score\": 0.04938271604938271,\n",
      "      \"support\": 35.0\n",
      "    },\n",
      "    \"lipid droplet\": {\n",
      "      \"precision\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"f1-score\": 0.0,\n",
      "      \"support\": 6.0\n",
      "    },\n",
      "    \"lysosome\": {\n",
      "      \"precision\": 0.007042253521126761,\n",
      "      \"recall\": 0.02247191011235955,\n",
      "      \"f1-score\": 0.010723860589812333,\n",
      "      \"support\": 89.0\n",
      "    },\n",
      "    \"microtubule organizing center\": {\n",
      "      \"precision\": 0.05785123966942149,\n",
      "      \"recall\": 0.06422018348623854,\n",
      "      \"f1-score\": 0.06086956521739131,\n",
      "      \"support\": 109.0\n",
      "    },\n",
      "    \"mitochondrion\": {\n",
      "      \"precision\": 0.012195121951219513,\n",
      "      \"recall\": 0.002881844380403458,\n",
      "      \"f1-score\": 0.004662004662004662,\n",
      "      \"support\": 347.0\n",
      "    },\n",
      "    \"nuclear chromosome\": {\n",
      "      \"precision\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"f1-score\": 0.0,\n",
      "      \"support\": 7.0\n",
      "    },\n",
      "    \"nuclear envelope\": {\n",
      "      \"precision\": 0.005128205128205128,\n",
      "      \"recall\": 0.1111111111111111,\n",
      "      \"f1-score\": 0.00980392156862745,\n",
      "      \"support\": 9.0\n",
      "    },\n",
      "    \"nucleolus\": {\n",
      "      \"precision\": 0.018691588785046728,\n",
      "      \"recall\": 0.05263157894736842,\n",
      "      \"f1-score\": 0.027586206896551724,\n",
      "      \"support\": 38.0\n",
      "    },\n",
      "    \"nucleoplasm\": {\n",
      "      \"precision\": 0.07894736842105263,\n",
      "      \"recall\": 0.031512605042016806,\n",
      "      \"f1-score\": 0.04504504504504504,\n",
      "      \"support\": 476.0\n",
      "    },\n",
      "    \"nucleus\": {\n",
      "      \"precision\": 0.3333333333333333,\n",
      "      \"recall\": 0.027874564459930314,\n",
      "      \"f1-score\": 0.05144694533762058,\n",
      "      \"support\": 1722.0\n",
      "    },\n",
      "    \"organelle\": {\n",
      "      \"precision\": 0.02242152466367713,\n",
      "      \"recall\": 0.05555555555555555,\n",
      "      \"f1-score\": 0.03194888178913738,\n",
      "      \"support\": 90.0\n",
      "    },\n",
      "    \"peroxisome\": {\n",
      "      \"precision\": 0.020202020202020204,\n",
      "      \"recall\": 0.1,\n",
      "      \"f1-score\": 0.03361344537815126,\n",
      "      \"support\": 20.0\n",
      "    },\n",
      "    \"plasma membrane\": {\n",
      "      \"precision\": 0.10476190476190476,\n",
      "      \"recall\": 0.018900343642611683,\n",
      "      \"f1-score\": 0.03202328966521106,\n",
      "      \"support\": 582.0\n",
      "    },\n",
      "    \"ribosome\": {\n",
      "      \"precision\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"f1-score\": 0.0,\n",
      "      \"support\": 68.0\n",
      "    },\n",
      "    \"vacuole\": {\n",
      "      \"precision\": 0.0047169811320754715,\n",
      "      \"recall\": 0.25,\n",
      "      \"f1-score\": 0.009259259259259259,\n",
      "      \"support\": 4.0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- EVALUATION EXAMPLE ---\n",
    "# Now, call the evaluation function with the test data and the trained model\n",
    "evaluation_results = evaluate_go_term_representations(df_test, topic_model, tokenizer_col, go_col)\n",
    "\n",
    "# Print the results in a readable format\n",
    "import json\n",
    "print(\"\\n--- GO Term Representation Evaluation Results ---\")\n",
    "print(json.dumps(evaluation_results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set (Multi-Label):   0%|          | 0/5886 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set (Multi-Label): 100%|██████████| 5886/5886 [00:04<00:00, 1268.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GO Term Representation Evaluation Results (Multi-Label) ---\n",
      "{\n",
      "  \"mean_reciprocal_rank\": 0.19873226921698717,\n",
      "  \"accuracy_at_k\": {\n",
      "    \"accuracy_at_1\": 0.07509344206591913,\n",
      "    \"accuracy_at_3\": 0.17040434930343187,\n",
      "    \"accuracy_at_5\": 0.25925925925925924,\n",
      "    \"accuracy_at_10\": 0.5524974515800204\n",
      "  },\n",
      "  \"precision_at_k\": {\n",
      "    \"precision_at_1\": 0.07509344206591913,\n",
      "    \"precision_at_3\": 0.06082229018008835,\n",
      "    \"precision_at_5\": 0.0600067957866123,\n",
      "    \"precision_at_10\": 0.07456676860346585\n",
      "  },\n",
      "  \"recall_at_k\": {\n",
      "    \"recall_at_1\": 0.04033744316618934,\n",
      "    \"recall_at_3\": 0.09345042581535955,\n",
      "    \"recall_at_5\": 0.15110033763193803,\n",
      "    \"recall_at_10\": 0.3924972628081701\n",
      "  },\n",
      "  \"classification_summary\": {\n",
      "    \"micro_avg\": {\n",
      "      \"precision\": 0.10294814674376718,\n",
      "      \"recall\": 0.10294814674376718,\n",
      "      \"f1-score\": 0.10294814674376718,\n",
      "      \"support\": 10549.0\n",
      "    },\n",
      "    \"macro_avg\": {\n",
      "      \"precision\": 0.11357729450920574,\n",
      "      \"recall\": 0.12520409218460718,\n",
      "      \"f1-score\": 0.07707491053560105,\n",
      "      \"support\": 10549.0\n",
      "    },\n",
      "    \"weighted_avg\": {\n",
      "      \"precision\": 0.22388477288329117,\n",
      "      \"recall\": 0.10294814674376718,\n",
      "      \"f1-score\": 0.09587889668403489,\n",
      "      \"support\": 10549.0\n",
      "    },\n",
      "    \"samples_avg\": {\n",
      "      \"precision\": 0.068753202379604,\n",
      "      \"recall\": 0.068753202379604,\n",
      "      \"f1-score\": 0.068753202379604,\n",
      "      \"support\": 10549.0\n",
      "    }\n",
      "  },\n",
      "  \"per_go_term_metrics\": {\n",
      "    \"Golgi apparatus\": {\n",
      "      \"precision\": 0.0723377832971127,\n",
      "      \"recall\": 0.5913705583756346,\n",
      "      \"f1-score\": 0.12890733056708162,\n",
      "      \"support\": 394.0\n",
      "    },\n",
      "    \"chromosome\": {\n",
      "      \"precision\": 0.07404692082111437,\n",
      "      \"recall\": 0.4611872146118721,\n",
      "      \"f1-score\": 0.12760581174984206,\n",
      "      \"support\": 219.0\n",
      "    },\n",
      "    \"cilium\": {\n",
      "      \"precision\": 0.08720112517580872,\n",
      "      \"recall\": 0.34444444444444444,\n",
      "      \"f1-score\": 0.13916947250280584,\n",
      "      \"support\": 180.0\n",
      "    },\n",
      "    \"cytoplasmic vesicle\": {\n",
      "      \"precision\": 0.12390488110137672,\n",
      "      \"recall\": 0.29464285714285715,\n",
      "      \"f1-score\": 0.17444933920704847,\n",
      "      \"support\": 336.0\n",
      "    },\n",
      "    \"cytoskeleton\": {\n",
      "      \"precision\": 0.22661870503597123,\n",
      "      \"recall\": 0.10824742268041238,\n",
      "      \"f1-score\": 0.14651162790697675,\n",
      "      \"support\": 582.0\n",
      "    },\n",
      "    \"cytosol\": {\n",
      "      \"precision\": 0.46296296296296297,\n",
      "      \"recall\": 0.13966480446927373,\n",
      "      \"f1-score\": 0.2145922746781116,\n",
      "      \"support\": 1253.0\n",
      "    },\n",
      "    \"endoplasmic reticulum\": {\n",
      "      \"precision\": 0.20962199312714777,\n",
      "      \"recall\": 0.1203155818540434,\n",
      "      \"f1-score\": 0.15288220551378445,\n",
      "      \"support\": 507.0\n",
      "    },\n",
      "    \"endosome\": {\n",
      "      \"precision\": 0.0784313725490196,\n",
      "      \"recall\": 0.04938271604938271,\n",
      "      \"f1-score\": 0.06060606060606061,\n",
      "      \"support\": 243.0\n",
      "    },\n",
      "    \"extracellular matrix\": {\n",
      "      \"precision\": 0.010309278350515464,\n",
      "      \"recall\": 0.031746031746031744,\n",
      "      \"f1-score\": 0.01556420233463035,\n",
      "      \"support\": 63.0\n",
      "    },\n",
      "    \"extracellular region\": {\n",
      "      \"precision\": 0.11602209944751381,\n",
      "      \"recall\": 0.0266497461928934,\n",
      "      \"f1-score\": 0.043343653250773995,\n",
      "      \"support\": 788.0\n",
      "    },\n",
      "    \"extracellular space\": {\n",
      "      \"precision\": 0.07563025210084033,\n",
      "      \"recall\": 0.07758620689655173,\n",
      "      \"f1-score\": 0.07659574468085106,\n",
      "      \"support\": 116.0\n",
      "    },\n",
      "    \"lipid droplet\": {\n",
      "      \"precision\": 0.010309278350515464,\n",
      "      \"recall\": 0.08695652173913043,\n",
      "      \"f1-score\": 0.018433179723502304,\n",
      "      \"support\": 23.0\n",
      "    },\n",
      "    \"lysosome\": {\n",
      "      \"precision\": 0.007731958762886598,\n",
      "      \"recall\": 0.02127659574468085,\n",
      "      \"f1-score\": 0.011342155009451797,\n",
      "      \"support\": 141.0\n",
      "    },\n",
      "    \"microtubule organizing center\": {\n",
      "      \"precision\": 0.17703349282296652,\n",
      "      \"recall\": 0.1712962962962963,\n",
      "      \"f1-score\": 0.17411764705882352,\n",
      "      \"support\": 216.0\n",
      "    },\n",
      "    \"mitochondrion\": {\n",
      "      \"precision\": 0.08088235294117647,\n",
      "      \"recall\": 0.045454545454545456,\n",
      "      \"f1-score\": 0.0582010582010582,\n",
      "      \"support\": 484.0\n",
      "    },\n",
      "    \"nuclear chromosome\": {\n",
      "      \"precision\": 0.009009009009009009,\n",
      "      \"recall\": 0.1,\n",
      "      \"f1-score\": 0.01652892561983471,\n",
      "      \"support\": 10.0\n",
      "    },\n",
      "    \"nuclear envelope\": {\n",
      "      \"precision\": 0.007722007722007722,\n",
      "      \"recall\": 0.044444444444444446,\n",
      "      \"f1-score\": 0.013157894736842105,\n",
      "      \"support\": 45.0\n",
      "    },\n",
      "    \"nucleolus\": {\n",
      "      \"precision\": 0.072,\n",
      "      \"recall\": 0.03515625,\n",
      "      \"f1-score\": 0.047244094488188976,\n",
      "      \"support\": 256.0\n",
      "    },\n",
      "    \"nucleoplasm\": {\n",
      "      \"precision\": 0.22745098039215686,\n",
      "      \"recall\": 0.05534351145038168,\n",
      "      \"f1-score\": 0.08902532617037605,\n",
      "      \"support\": 1048.0\n",
      "    },\n",
      "    \"nucleus\": {\n",
      "      \"precision\": 0.3618421052631579,\n",
      "      \"recall\": 0.029617662897145933,\n",
      "      \"f1-score\": 0.0547536087605774,\n",
      "      \"support\": 1857.0\n",
      "    },\n",
      "    \"organelle\": {\n",
      "      \"precision\": 0.0979020979020979,\n",
      "      \"recall\": 0.06965174129353234,\n",
      "      \"f1-score\": 0.08139534883720931,\n",
      "      \"support\": 402.0\n",
      "    },\n",
      "    \"peroxisome\": {\n",
      "      \"precision\": 0.017857142857142856,\n",
      "      \"recall\": 0.06060606060606061,\n",
      "      \"f1-score\": 0.027586206896551724,\n",
      "      \"support\": 33.0\n",
      "    },\n",
      "    \"plasma membrane\": {\n",
      "      \"precision\": 0.225,\n",
      "      \"recall\": 0.022203947368421052,\n",
      "      \"f1-score\": 0.040419161676646706,\n",
      "      \"support\": 1216.0\n",
      "    },\n",
      "    \"ribosome\": {\n",
      "      \"precision\": 0.0,\n",
      "      \"recall\": 0.0,\n",
      "      \"f1-score\": 0.0,\n",
      "      \"support\": 123.0\n",
      "    },\n",
      "    \"vacuole\": {\n",
      "      \"precision\": 0.0076045627376425855,\n",
      "      \"recall\": 0.14285714285714285,\n",
      "      \"f1-score\": 0.01444043321299639,\n",
      "      \"support\": 14.0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- MULTI-LABEL EVALUATION EXAMPLE ---\n",
    "# Call the new multi-label evaluation function\n",
    "multilabel_evaluation_results = evaluate_go_term_representations_multilabel(df_test, topic_model, tokenizer_col, go_col)\n",
    "\n",
    "print(\"\\n--- GO Term Representation Evaluation Results (Multi-Label) ---\")\n",
    "print(json.dumps(multilabel_evaluation_results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
