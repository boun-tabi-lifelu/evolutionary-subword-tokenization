{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e24ab9",
   "metadata": {},
   "source": [
    "# Notebook corresponding to case studies taken from MaveDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b548369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6ae51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/cta/share/users/ProteinGym/Clinical_Variants(Substitutions)/NP_003110.1.csv'),\n",
       " PosixPath('/cta/share/users/ProteinGym/Clinical_Variants(Substitutions)/NP_005076.3.csv'),\n",
       " PosixPath('/cta/share/users/ProteinGym/Clinical_Variants(Substitutions)/NP_005493.2.csv'),\n",
       " PosixPath('/cta/share/users/ProteinGym/Clinical_Variants(Substitutions)/NP_057097.2.csv'),\n",
       " PosixPath('/cta/share/users/ProteinGym/Clinical_Variants(Substitutions)/NP_055790.1.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "base_path = Path(\"/cta/share/users/ProteinGym/Clinical_Variants(Substitutions)\")\n",
    "list(base_path.glob(\"*.csv\"))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee12e2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>protein</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>mutant</th>\n",
       "      <th>mutated_sequence</th>\n",
       "      <th>DMS_bin_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67567</td>\n",
       "      <td>NP_003110.1</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>R13G</td>\n",
       "      <td>MAVLLLLLRALRGGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67568</td>\n",
       "      <td>NP_003110.1</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>G32E</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPEFPARPGRGRPYMAS...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67569</td>\n",
       "      <td>NP_003110.1</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>K113R</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67572</td>\n",
       "      <td>NP_003110.1</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>V183I</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67573</td>\n",
       "      <td>NP_003110.1</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>R294H</td>\n",
       "      <td>MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62715</th>\n",
       "      <td>18955</td>\n",
       "      <td>NP_004647.1</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>S596G</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62717</th>\n",
       "      <td>18957</td>\n",
       "      <td>NP_004647.1</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>V476A</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62718</th>\n",
       "      <td>18958</td>\n",
       "      <td>NP_004647.1</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>T423K</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62719</th>\n",
       "      <td>18959</td>\n",
       "      <td>NP_004647.1</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>N290S</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62725</th>\n",
       "      <td>18965</td>\n",
       "      <td>NP_004647.1</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...</td>\n",
       "      <td>G41S</td>\n",
       "      <td>MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQSPVYGF...</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30727 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      protein  \\\n",
       "0           67567  NP_003110.1   \n",
       "1           67568  NP_003110.1   \n",
       "2           67569  NP_003110.1   \n",
       "5           67572  NP_003110.1   \n",
       "6           67573  NP_003110.1   \n",
       "...           ...          ...   \n",
       "62715       18955  NP_004647.1   \n",
       "62717       18957  NP_004647.1   \n",
       "62718       18958  NP_004647.1   \n",
       "62719       18959  NP_004647.1   \n",
       "62725       18965  NP_004647.1   \n",
       "\n",
       "                                        protein_sequence mutant  \\\n",
       "0      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...   R13G   \n",
       "1      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...   G32E   \n",
       "2      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...  K113R   \n",
       "5      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...  V183I   \n",
       "6      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...  R294H   \n",
       "...                                                  ...    ...   \n",
       "62715  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...  S596G   \n",
       "62717  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...  V476A   \n",
       "62718  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...  T423K   \n",
       "62719  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...  N290S   \n",
       "62725  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...   G41S   \n",
       "\n",
       "                                        mutated_sequence DMS_bin_score  \n",
       "0      MAVLLLLLRALRGGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...        Benign  \n",
       "1      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPEFPARPGRGRPYMAS...        Benign  \n",
       "2      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...        Benign  \n",
       "5      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...        Benign  \n",
       "6      MAVLLLLLRALRRGPGPGPRPLWGPGPAWSPGFPARPGRGRPYMAS...        Benign  \n",
       "...                                                  ...           ...  \n",
       "62715  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...        Benign  \n",
       "62717  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...        Benign  \n",
       "62718  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...        Benign  \n",
       "62719  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQGPVYGF...        Benign  \n",
       "62725  MNKGWLELESDPGLFTLLVEDFGVKGVQVEEIYDLQSKCQSPVYGF...        Benign  \n",
       "\n",
       "[30727 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Use a generator expression to read and concatenate CSVs\n",
    "df = pd.concat((pd.read_csv(file) for file in base_path.rglob(\"*.csv\")), ignore_index=True)\n",
    "# df = pd.read_csv('/cta/share/users/ProteinGym/Clinical_Variants(Substitutions)/NP_055790.1.csv')\n",
    "df[df[\"DMS_bin_score\"] == \"Benign\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6617469",
   "metadata": {},
   "source": [
    "# Apply segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e5b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tokenizers import Tokenizer\n",
    "from vocabulary_functions import calc_dice_from_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551ebd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz_path = \"/cta/share/users/mutbpe/tokenizers/blosum62/hf_uniref50_bpe_51200.json\"\n",
    "tkz1 = Tokenizer.from_file(tkz_path)\n",
    "tkz_path = \"/cta/share/users/mutbpe/tokenizers/blosum62/hf_uniref50_mutbpe_0.7_3_12_0.05_51200.json\"\n",
    "tkz2 = Tokenizer.from_file(tkz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b41f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Given a Tokenizers encoding offsets offs\n",
    "Assign each symbol in the sequence its token id\n",
    "Return the numpy list containing assignments\n",
    "(Like cluster assignments)\n",
    "'''\n",
    "def _offsets_to_cluster(offs):\n",
    "    seq_len = offs[-1][-1]\n",
    "    cluster_assign = np.zeros((seq_len, 1))\n",
    "    for i, (b, e) in enumerate(offs):\n",
    "        cluster_assign[b:e] = i\n",
    "    return cluster_assign\n",
    "\n",
    "\n",
    "# Cluster based rand-index\n",
    "def calc_rand_index(offs1, offs2):\n",
    "    clusters1 = _offsets_to_cluster(offs1)\n",
    "    clusters2 = _offsets_to_cluster(offs2)\n",
    "    assign_eq = pdist(clusters1, metric='hamming')  # 0 if same, 1 if different\n",
    "    label_eq = pdist(clusters2, metric='hamming') # 0 if same, 1 if different\n",
    "    rand_index = np.mean(assign_eq == label_eq)\n",
    "    return rand_index\n",
    "\n",
    "# Cluster based dice index\n",
    "def calc_dice_index(offs1, offs2):\n",
    "    clusters1 = _offsets_to_cluster(offs1)\n",
    "    clusters2 = _offsets_to_cluster(offs2)\n",
    "    assign_eq = pdist(clusters1, metric='hamming')  # 0 if same, 1 if different\n",
    "    label_eq = pdist(clusters2, metric='hamming') # 0 if same, 1 if different\n",
    "    # Boolean masks\n",
    "    same_assign = assign_eq == 0\n",
    "    same_label = label_eq == 0\n",
    "    TP = np.sum(same_assign & same_label)\n",
    "    FP = np.sum(same_assign & ~same_label)\n",
    "    FN = np.sum(~same_assign & same_label)\n",
    "    # Jaccard index (ignores TN)\n",
    "    dice_index = 2*TP / (2*TP + FP + FN + 1e-10)\n",
    "    return dice_index\n",
    "\n",
    "# Cluster based jaccard index\n",
    "def calc_jaccard_index(offs1, offs2):\n",
    "    clusters1 = _offsets_to_cluster(offs1)\n",
    "    clusters2 = _offsets_to_cluster(offs2)\n",
    "    assign_eq = pdist(clusters1, metric='hamming')  # 0 if same, 1 if different\n",
    "    label_eq = pdist(clusters2, metric='hamming') # 0 if same, 1 if different\n",
    "    # Boolean masks\n",
    "    same_assign = assign_eq == 0\n",
    "    same_label = label_eq == 0\n",
    "    TP = np.sum(same_assign & same_label)\n",
    "    FP = np.sum(same_assign & ~same_label)\n",
    "    FN = np.sum(~same_assign & same_label)\n",
    "    # Jaccard index (ignores TN)\n",
    "    jaccard_index = TP / (TP + FP + FN + 1e-10)\n",
    "    return jaccard_index\n",
    "\n",
    "# Calc all indices at the same time to avoid redundancy\n",
    "# Returns rand, dice, jaccard\n",
    "def calc_all_indices(offs1, offs2):\n",
    "    clusters1 = _offsets_to_cluster(offs1)\n",
    "    clusters2 = _offsets_to_cluster(offs2)\n",
    "    assign_eq = pdist(clusters1, metric='hamming')  # 0 if same, 1 if different\n",
    "    label_eq = pdist(clusters2, metric='hamming') # 0 if same, 1 if different\n",
    "    same_assign = assign_eq == 0\n",
    "    same_label = label_eq == 0\n",
    "    TP = np.sum(same_assign & same_label)\n",
    "    FP = np.sum(same_assign & ~same_label)\n",
    "    FN = np.sum(~same_assign & same_label)\n",
    "    TN = np.sum(~same_assign & ~same_label)\n",
    "\n",
    "\n",
    "    jaccard_index = TP / (TP + FP + FN + 1e-10)\n",
    "    dice_index = 2*TP / (2*TP + FP + FN + 1e-10)\n",
    "    rand_index = (TP + TN) / (TP + FP + FN + TN)\n",
    "    \n",
    "    return rand_index, dice_index, jaccard_index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b104d2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE Path 14329\n",
      "PUMA Path 15045\n",
      "BPE Benign 16018\n",
      "PUMA Benign 16794\n"
     ]
    }
   ],
   "source": [
    "def batch_calc(tkz, ref_list, target_list):\n",
    "    scores = np.zeros((len(target_list), 4))\n",
    "    for i, seq in enumerate(target_list):\n",
    "        ref_seq = ref_list[i]\n",
    "        ref_enc = tkz.encode(ref_seq)\n",
    "        mutated_enc = tkz.encode(seq)\n",
    "        scores[i, :] = np.array([\n",
    "                calc_rand_index(ref_enc, mutated_enc),\n",
    "                calc_dice_from_encodings((ref_enc, mutated_enc)),\n",
    "                calc_dice_index(ref_enc, mutated_enc),\n",
    "                calc_jaccard_index(ref_enc, mutated_enc)\n",
    "        ])\n",
    "    return scores.mean(axis = 0)\n",
    "\n",
    "def batch_calc_eq(tkz, ref_list, target_list):\n",
    "    ct = 0\n",
    "    for i, seq in enumerate(target_list):\n",
    "        ref_seq = ref_list[i]\n",
    "        ref_enc = tkz.encode(ref_seq)\n",
    "        mutated_enc = tkz.encode(seq)\n",
    "        if ref_enc.offsets == mutated_enc.offsets:\n",
    "            ct += 1\n",
    "    return ct\n",
    "        \n",
    "df_benign = df[df[\"DMS_bin_score\"] == \"Benign\"]\n",
    "df_patho = df[df[\"DMS_bin_score\"] == \"Pathogenic\"]\n",
    "print(\"BPE Path\", batch_calc_eq(tkz1, df_patho[\"protein_sequence\"].to_list()[:30000], df_patho[\"mutated_sequence\"].to_list()[:30000]))\n",
    "print(\"PUMA Path\", batch_calc_eq(tkz2, df_patho[\"protein_sequence\"].to_list()[:30000], df_patho[\"mutated_sequence\"].to_list()[:30000]))\n",
    "print(\"BPE Benign\", batch_calc_eq(tkz1, df_benign[\"protein_sequence\"].to_list()[:30000], df_benign[\"mutated_sequence\"].to_list()[:30000]))\n",
    "print(\"PUMA Benign\", batch_calc_eq(tkz2, df_benign[\"protein_sequence\"].to_list()[:30000], df_benign[\"mutated_sequence\"].to_list()[:30000]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5458204",
   "metadata": {},
   "source": [
    "# Notlar\n",
    "- Ayni kalan proteinler ne kadar ayni iki algoritma arasinda.\n",
    "- DMS datasindaki, fonksiyonel olarak coherent butun parcalar ile bizim tokenlarimiz arasinda bir uyusma var mi diye incele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffc2d622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"DMS_bin_score\"] == \"Pathogenic\"].__len__()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1373e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32000it [01:28, 360.28it/s] \n"
     ]
    }
   ],
   "source": [
    "encs1 = tkz1.encode_batch(df_patho[\"protein_sequence\"])\n",
    "encs2 = tkz1.encode_batch(df_patho[\"mutated_sequence\"])\n",
    "from tqdm import tqdm\n",
    "data = []\n",
    "for enc1, enc2 in tqdm(zip(encs1, encs2)):\n",
    "    data.append(calc_all_indices(enc1, enc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30d410d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encs1[1].offsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf284cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "attribute 'offsets' of 'tokenizers.Encoding' objects is not writable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m new1 \u001b[38;5;241m=\u001b[39m take_offsets_subset(offsets1, lower_idx, upper_idx)\n\u001b[1;32m     45\u001b[0m new2 \u001b[38;5;241m=\u001b[39m take_offsets_subset(offsets2, lower_idx, upper_idx)\n\u001b[0;32m---> 46\u001b[0m \u001b[43menc1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffsets\u001b[49m \u001b[38;5;241m=\u001b[39m new1\n\u001b[1;32m     47\u001b[0m enc2\u001b[38;5;241m.\u001b[39moffsets \u001b[38;5;241m=\u001b[39m new2\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(calc_all_indices(enc1, enc2))\n",
      "\u001b[0;31mAttributeError\u001b[0m: attribute 'offsets' of 'tokenizers.Encoding' objects is not writable"
     ]
    }
   ],
   "source": [
    "def take_offsets_subset(offs, lower_idx, upper_idx):\n",
    "    new_offsets = []\n",
    "    for s,e in offs:\n",
    "        start, end = 0, 0\n",
    "        if e <= lower_idx:\n",
    "            continue\n",
    "        if s > upper_idx:\n",
    "            continue\n",
    "        if s < lower_idx:\n",
    "            start = 0\n",
    "        else:\n",
    "            start = s - lower_idx\n",
    "        if e > upper_idx:\n",
    "            end = upper_idx - lower_idx + 1\n",
    "        else:\n",
    "            end = e - lower_idx\n",
    "        new_offsets.append((start, end))\n",
    "    return new_offsets\n",
    "\n",
    "\n",
    "# Instead of calculating the metrics through whole sequence, calculate them on a short window around the mutation.\n",
    "mutants = df_patho[\"mutant\"].to_list()\n",
    "mutants = [int(mut[1:-1]) for mut in mutants]\n",
    "for i, (enc1, enc2) in tqdm(enumerate(zip(encs1, encs2))):\n",
    "    offsets1 = enc1.offsets.copy()\n",
    "    offsets2 = enc2.offsets.copy()\n",
    "    if offsets1 == offsets2:\n",
    "        print(calc_all_indices(enc1, enc2))\n",
    "    seq_len = offsets1[-1][-1]\n",
    "    mutation_pos = mutants[i]\n",
    "    if seq_len <= 100:\n",
    "        print(\"less than 101\")\n",
    "        pass # stop calculating\n",
    "    else:\n",
    "        # Window size 101\n",
    "        upper_idx = mutation_pos + 50\n",
    "        lower_idx = mutation_pos - 50\n",
    "        if upper_idx >= seq_len:\n",
    "            lower_idx += -(upper_idx - seq_len + 1)\n",
    "            upper_idx = seq_len - 1\n",
    "        if lower_idx < 0:\n",
    "            upper_idx -= lower_idx\n",
    "            lower_idx = 0\n",
    "        new1 = take_offsets_subset(offsets1, lower_idx, upper_idx)\n",
    "        new2 = take_offsets_subset(offsets2, lower_idx, upper_idx)\n",
    "        enc1.offsets = new1\n",
    "        enc2.offsets = new2\n",
    "        print(calc_all_indices(enc1, enc2))\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee372dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "a.clear()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8442c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
